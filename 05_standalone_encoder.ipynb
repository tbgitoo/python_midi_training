{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "643329ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Standalone Keras Encoder Built with FINAL Corrected Naming ---\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 32, 90)]          0         \n",
      "                                                                 \n",
      " cell_0 (Functional)         (None, 4096)              35045376  \n",
      "                                                                 \n",
      " mu (Dense)                  (None, 512)               2097664   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,143,040\n",
      "Trainable params: 37,143,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "from magenta.models.music_vae import configs\n",
    "\n",
    "import numpy as np\n",
    "from magenta.models.music_vae.trained_model import TrainedModel # We need this class\n",
    "\n",
    "def build_standalone_encoder(hparams, input_shape):\n",
    "    \"\"\"\n",
    "    Builds a standard Keras model that replicates the custom BidirectionalLstmEncoder.\n",
    "    \n",
    "    Args:\n",
    "        hparams: The same hparams object used by the original model.\n",
    "        input_shape: The shape of a single input sequence (e.g., (96, 64)).\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Define the input layer\n",
    "    input_tensor = tf.keras.layers.Input(shape=input_shape, name='encoder_input')\n",
    "    \n",
    "    # 2. Re-create the stacked LSTM cells as Keras layers\n",
    "    # The original code uses a shared cell for fw and bw. The modern equivalent\n",
    "    # is to create one stack of LSTM layers and wrap it in Bidirectional.\n",
    "    \n",
    "    # Start with the input tensor\n",
    "    x = input_tensor\n",
    "    \n",
    "    # Create the stack of LSTM layers\n",
    "    # The `return_sequences=True` is crucial for all but the last layer in a stack.\n",
    "    num_lstm_layers = len(hparams.enc_rnn_size)\n",
    "    for i, layer_size in enumerate(hparams.enc_rnn_size):\n",
    "        lstm_layer = tf.keras.layers.LSTM(\n",
    "            units=layer_size, \n",
    "            return_sequences=False, # The last (and only) LSTM returns a single vector\n",
    "            name='multi_rnn_cell/cell_0/lstm_cell' # CRITICAL: Match TF1 variable scope\n",
    "        )\n",
    "        \n",
    "        bi_lstm = tf.keras.layers.Bidirectional(\n",
    "            lstm_layer,\n",
    "            name='bidirectional_rnn' # CRITICAL: Match TF1 variable scope\n",
    "        )\n",
    "\n",
    "        # To create the 'cell_0' scope, we wrap the Bidirectional layer in a tiny sub-model\n",
    "        # This is the key to matching the checkpoint's variable names.\n",
    "        bi_lstm_model = tf.keras.Model(inputs=x, outputs=bi_lstm(x), name=f'cell_{i}')\n",
    "        x = bi_lstm_model(x)\n",
    "\n",
    "    # 3. Replicate the flatten operation\n",
    "    # The original code flattens, but since the last LSTM returns a single vector per direction,\n",
    "    # the output of Bidirectional is already \"flat\" in the time dimension.\n",
    "    \n",
    "    # 4. Re-create the final Dense layers\n",
    "    # This layer needs to be inside an 'encoder' scope, which we will achieve by wrapping the whole thing.\n",
    "    mu_layer = tf.keras.layers.Dense(hparams.z_size, name='mu')\n",
    "    \n",
    "    # The final output of our model is just the embedding (mu)\n",
    "    mu_output = mu_layer(x)\n",
    "    \n",
    "    # 5. Create and return the final Keras model\n",
    "    # We name the final model 'encoder' to add the last required scope.\n",
    "    encoder_model = tf.keras.Model(inputs=input_tensor, outputs=mu_output, name='encoder')\n",
    "    \n",
    "    print(\"--- Standalone Keras Encoder Built with FINAL Corrected Naming ---\")\n",
    "    encoder_model.summary()\n",
    "    \n",
    "    return encoder_model\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# You would get `your_hparams` from the `mel_2bar._config.hparams` object\n",
    "mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
    "\n",
    "# Derive the input_shape from the config\n",
    "# At present mel_2bar_config.data_converter.input_depth is 90 (for 88 piano keys + 2 possibly special tokens)\n",
    "# and mel_2bar_config.hparams.max_seq_len is 32 (for 2 bars of 16 steps each)\n",
    "encoder_input_shape = (mel_2bar_config.hparams.max_seq_len, mel_2bar_config.data_converter.input_depth)\n",
    "\n",
    "standalone_encoder = build_standalone_encoder(mel_2bar_config.hparams, input_shape=encoder_input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7db3e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model loaded successfully.\n",
      "\n",
      "--- Step 2: Building the new standalone TF2 Keras encoder ---\n",
      "--- Standalone Keras Encoder Built with FINAL Corrected Naming ---\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 32, 90)]          0         \n",
      "                                                                 \n",
      " cell_0 (Functional)         (None, 4096)              35045376  \n",
      "                                                                 \n",
      " mu (Dense)                  (None, 512)               2097664   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,143,040\n",
      "Trainable params: 37,143,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "--- Step 3: Starting weight transfer from TF1 session to TF2 model ---\n",
      "\n",
      "Processing layer: cell_0/bidirectional_rnn\n",
      "  - Successfully split kernels and transferred 6 weights for Bidirectional LSTM.\n",
      "\n",
      "Processing layer: mu\n",
      "  - Successfully transferred weights for Dense layer 'mu'.\n",
      "\n",
      "--- Step 4: Weight transfer complete. Saving the new Keras model. ---\n",
      "\n",
      "Successfully saved the new Keras model to: 'models/music_vae_encoder_keras'\n"
     ]
    }
   ],
   "source": [
    "# Use tensorflow.compat.v1 and disable V2 behavior\n",
    "\n",
    "sess = mel_2bar._sess\n",
    "print(\"Original model loaded successfully.\")\n",
    "\n",
    "print(\"\\n--- Step 2: Building the new standalone TF2 Keras encoder ---\")\n",
    "encoder_input_shape = (mel_2bar_config.hparams.max_seq_len, mel_2bar_config.data_converter.input_depth)\n",
    "standalone_encoder = build_standalone_encoder(mel_2bar_config.hparams, input_shape=encoder_input_shape)\n",
    "\n",
    "print(\"\\n--- Step 3: Starting weight transfer from TF1 session to TF2 model ---\")\n",
    "tf1_variables = sess.graph.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "tf1_variable_names = [v.name for v in tf1_variables]\n",
    "tf1_variable_values = sess.run(tf1_variables)\n",
    "tf1_weights_map = dict(zip(tf1_variable_names, tf1_variable_values))\n",
    "\n",
    "# Iterate through the layers of our new Keras model to set their weights\n",
    "for layer in standalone_encoder.layers:\n",
    "    if layer.name == 'cell_0': # This is our Bidirectional sub-model\n",
    "        for sub_layer in layer.layers:\n",
    "            if isinstance(sub_layer, tf.keras.layers.Bidirectional):\n",
    "                print(f\"\\nProcessing layer: {layer.name}/{sub_layer.name}\")\n",
    "                \n",
    "                # Get the names for the combined kernel and bias from the TF1 checkpoint\n",
    "                fw_kernel_name = 'encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel:0'\n",
    "                fw_bias_name = 'encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias:0'\n",
    "                bw_kernel_name = 'encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel:0'\n",
    "                bw_bias_name = 'encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias:0'\n",
    "                \n",
    "                try:\n",
    "                    # --- KERNEL SPLITTING LOGIC ---\n",
    "                    input_depth = mel_2bar_config.data_converter.input_depth\n",
    "                    \n",
    "                    # Get the combined kernels from the checkpoint\n",
    "                    fw_kernel_combined = tf1_weights_map[fw_kernel_name]\n",
    "                    bw_kernel_combined = tf1_weights_map[bw_kernel_name]\n",
    "                    \n",
    "                    # Split the forward kernel\n",
    "                    fw_input_kernel = fw_kernel_combined[:input_depth, :]\n",
    "                    fw_recurrent_kernel = fw_kernel_combined[input_depth:, :]\n",
    "                    \n",
    "                    # Split the backward kernel\n",
    "                    bw_input_kernel = bw_kernel_combined[:input_depth, :]\n",
    "                    bw_recurrent_kernel = bw_kernel_combined[input_depth:, :]\n",
    "                    \n",
    "                    # Get the biases\n",
    "                    fw_bias = tf1_weights_map[fw_bias_name]\n",
    "                    bw_bias = tf1_weights_map[bw_bias_name]\n",
    "                    \n",
    "                    # Assemble the list of 6 weights in the correct order for Keras\n",
    "                    keras_weights = [\n",
    "                        fw_input_kernel, fw_recurrent_kernel, fw_bias,\n",
    "                        bw_input_kernel, bw_recurrent_kernel, bw_bias\n",
    "                    ]\n",
    "                    \n",
    "                    # Set the 6 weights on the Bidirectional layer\n",
    "                    sub_layer.set_weights(keras_weights)\n",
    "                    print(f\"  - Successfully split kernels and transferred 6 weights for Bidirectional LSTM.\")\n",
    "\n",
    "                except KeyError as e:\n",
    "                    print(f\"  - FATAL ERROR: Could not find weight {e}!\")\n",
    "                except ValueError as e:\n",
    "                    print(f\"  - FATAL ERROR during set_weights: {e}\")\n",
    "\n",
    "    if layer.name == 'mu' and isinstance(layer, tf.keras.layers.Dense):\n",
    "        print(f\"\\nProcessing layer: {layer.name}\")\n",
    "        kernel_name = f'encoder/mu/kernel:0'\n",
    "        bias_name = f'encoder/mu/bias:0'\n",
    "        try:\n",
    "            layer.set_weights([\n",
    "                tf1_weights_map[kernel_name],\n",
    "                tf1_weights_map[bias_name]\n",
    "            ])\n",
    "            print(f\"  - Successfully transferred weights for Dense layer 'mu'.\")\n",
    "        except KeyError as e:\n",
    "            print(f\"  - FATAL ERROR: Could not find weight {e} for 'mu' layer!\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- Step 4: Weight transfer complete. Saving the new Keras model. ---\")\n",
    "\n",
    "output_keras_model_path = 'models/music_vae_encoder_keras'\n",
    "tf.keras.models.save_model(standalone_encoder, output_keras_model_path)\n",
    "\n",
    "print(f\"\\nSuccessfully saved the new Keras model to: '{output_keras_model_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c01b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tensorflow.compat.v1 and disable V2 behavior for the original model\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "from magenta.models.music_vae import configs\n",
    "from magenta.models.music_vae.trained_model import TrainedModel\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. SETUP & MODEL LOADING\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"--- Step 1: Loading original TF1-style MusicVAE model ---\")\n",
    "\n",
    "# Use a batch size of 1 for easier comparison\n",
    "BATCH_SIZE = 1\n",
    "mel_2bar = TrainedModel(mel_2bar_config, batch_size=BATCH_SIZE, checkpoint_dir_or_path=checkpoint_path)\n",
    "sess = mel_2bar._sess\n",
    "print(\"Original model loaded.\")\n",
    "\n",
    "print(\"\\n--- Step 2: Loading the new standalone Keras encoder ---\")\n",
    "keras_model_path = 'model/music_vae_encoder_keras'\n",
    "# We can load the Keras model using the modern API\n",
    "standalone_encoder = tf.keras.models.load_model(keras_model_path)\n",
    "print(\"New Keras model loaded.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. INFERENCE & COMPARISON\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- Step 3: Generating a random input tensor ---\")\n",
    "# Get the expected input shape from the config\n",
    "seq_len = mel_2bar_config.hparams.max_seq_len\n",
    "input_depth = mel_2bar_config.data_converter.input_depth\n",
    "input_shape = (BATCH_SIZE, seq_len, input_depth)\n",
    "\n",
    "# Create a random input tensor\n",
    "random_input = np.random.rand(*input_shape).astype(np.float32)\n",
    "print(f\"Generated random input with shape: {random_input.shape}\")\n",
    "\n",
    "print(\"\\n--- Step 4: Running inference on both models ---\")\n",
    "\n",
    "# --- Get embedding from the ORIGINAL TF1 model ---\n",
    "# We need to feed the input tensor and the sequence length to the session\n",
    "feed_dict = {\n",
    "    mel_2bar._inputs: random_input,\n",
    "    # For a full-length random input, the length is the max sequence length\n",
    "    mel_2bar._inputs_length: [seq_len] * BATCH_SIZE\n",
    "}\n",
    "# `_mu` is the tensor that holds the embedding (the mean of the latent distribution)\n",
    "original_embedding = sess.run(mel_2bar._mu, feed_dict)\n",
    "\n",
    "\n",
    "# --- Get embedding from the NEW Keras model ---\n",
    "# The Keras model's predict method is much simpler\n",
    "keras_embedding = standalone_encoder.predict(random_input)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. VERIFICATION\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- Step 5: Comparing the outputs ---\")\n",
    "print(f\"Original model's embedding (first 5 values): {original_embedding[0, :5]}\")\n",
    "print(f\"New Keras model's embedding (first 5 values):  {keras_embedding[0, :5]}\")\n",
    "\n",
    "# Compare the two embeddings for near-perfect equality\n",
    "# np.allclose is essential for comparing floating-point numbers\n",
    "are_close = np.allclose(original_embedding, keras_embedding, atol=1e-6)\n",
    "\n",
    "print(\"\\n--- VERIFICATION RESULT ---\")\n",
    "if are_close:\n",
    "    print(\"✅ SUCCESS: The embeddings from both models are identical!\")\n",
    "    # Calculate the absolute difference for confirmation\n",
    "    abs_diff = np.mean(np.abs(original_embedding - keras_embedding))\n",
    "    print(f\"   (Mean absolute difference: {abs_diff:.10f})\")\n",
    "else:\n",
    "    print(\"❌ FAILURE: The embeddings do not match.\")\n",
    "    # Calculate the absolute difference to see how far off they are\n",
    "    abs_diff = np.mean(np.abs(original_embedding - keras_embedding))\n",
    "    print(f\"   (Mean absolute difference: {abs_diff})\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
