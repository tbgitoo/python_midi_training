{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "643329ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Standalone Keras Encoder Built with FINAL Corrected Naming ---\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 32, 90)]          0         \n",
      "                                                                 \n",
      " cell_0 (Functional)         (None, 4096)              35045376  \n",
      "                                                                 \n",
      " mu (Dense)                  (None, 512)               2097664   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,143,040\n",
      "Trainable params: 37,143,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "from magenta.models.music_vae import configs\n",
    "\n",
    "import numpy as np\n",
    "from magenta.models.music_vae.trained_model import TrainedModel # We need this class\n",
    "\n",
    "def build_standalone_encoder(hparams, input_shape):\n",
    "    \"\"\"\n",
    "    Builds a standard Keras model that replicates the custom BidirectionalLstmEncoder.\n",
    "    \n",
    "    Args:\n",
    "        hparams: The same hparams object used by the original model.\n",
    "        input_shape: The shape of a single input sequence (e.g., (96, 64)).\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Define the input layer\n",
    "    input_tensor = tf.keras.layers.Input(shape=input_shape, name='encoder_input')\n",
    "    \n",
    "    # 2. Re-create the stacked LSTM cells as Keras layers\n",
    "    # The original code uses a shared cell for fw and bw. The modern equivalent\n",
    "    # is to create one stack of LSTM layers and wrap it in Bidirectional.\n",
    "    \n",
    "    # Start with the input tensor\n",
    "    x = input_tensor\n",
    "    \n",
    "    # Create the stack of LSTM layers\n",
    "    # The `return_sequences=True` is crucial for all but the last layer in a stack.\n",
    "    num_lstm_layers = len(hparams.enc_rnn_size)\n",
    "    for i, layer_size in enumerate(hparams.enc_rnn_size):\n",
    "        lstm_layer = tf.keras.layers.LSTM(\n",
    "            units=layer_size, \n",
    "            return_sequences=False, # The last (and only) LSTM returns a single vector\n",
    "            name='multi_rnn_cell/cell_0/lstm_cell' # CRITICAL: Match TF1 variable scope\n",
    "        )\n",
    "        \n",
    "        bi_lstm = tf.keras.layers.Bidirectional(\n",
    "            lstm_layer,\n",
    "            name='bidirectional_rnn' # CRITICAL: Match TF1 variable scope\n",
    "        )\n",
    "\n",
    "        # To create the 'cell_0' scope, we wrap the Bidirectional layer in a tiny sub-model\n",
    "        # This is the key to matching the checkpoint's variable names.\n",
    "        bi_lstm_model = tf.keras.Model(inputs=x, outputs=bi_lstm(x), name=f'cell_{i}')\n",
    "        x = bi_lstm_model(x)\n",
    "\n",
    "    # 3. Replicate the flatten operation\n",
    "    # The original code flattens, but since the last LSTM returns a single vector per direction,\n",
    "    # the output of Bidirectional is already \"flat\" in the time dimension.\n",
    "    \n",
    "    # 4. Re-create the final Dense layers\n",
    "    # This layer needs to be inside an 'encoder' scope, which we will achieve by wrapping the whole thing.\n",
    "    mu_layer = tf.keras.layers.Dense(hparams.z_size, name='mu')\n",
    "    \n",
    "    # The final output of our model is just the embedding (mu)\n",
    "    mu_output = mu_layer(x)\n",
    "    \n",
    "    # 5. Create and return the final Keras model\n",
    "    # We name the final model 'encoder' to add the last required scope.\n",
    "    encoder_model = tf.keras.Model(inputs=input_tensor, outputs=mu_output, name='encoder')\n",
    "    \n",
    "    print(\"--- Standalone Keras Encoder Built with FINAL Corrected Naming ---\")\n",
    "    encoder_model.summary()\n",
    "    \n",
    "    return encoder_model\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# You would get `your_hparams` from the `mel_2bar._config.hparams` object\n",
    "mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
    "\n",
    "# Derive the input_shape from the config\n",
    "# At present mel_2bar_config.data_converter.input_depth is 90 (for 88 piano keys + 2 possibly special tokens)\n",
    "# and mel_2bar_config.hparams.max_seq_len is 32 (for 2 bars of 16 steps each)\n",
    "encoder_input_shape = (mel_2bar_config.hparams.max_seq_len, mel_2bar_config.data_converter.input_depth)\n",
    "\n",
    "standalone_encoder = build_standalone_encoder(mel_2bar_config.hparams, input_shape=encoder_input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7db3e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading original TF1-style MusicVAE model ---\n",
      "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n",
      "{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
      "INFO:tensorflow:\n",
      "Encoder Cells (bidirectional):\n",
      "  units: [2048]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [2048, 2048, 2048]\n",
      "\n",
      "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\models\\music_vae\\lstm_utils.py:94: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  tf.layers.dense(\n",
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\contrib\\rnn.py:749: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  self._kernel = self.add_variable(\n",
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\contrib\\rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  self._bias = self.add_variable(\n",
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\models\\music_vae\\base_model.py:195: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  mu = tf.layers.dense(\n",
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\models\\music_vae\\base_model.py:200: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  sigma = tf.layers.dense(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/download.magenta.tensorflow.org/models/music_vae/checkpoints/mel_2bar_big.ckpt\n",
      "Original model loaded successfully.\n",
      "\n",
      "--- Step 2: Building the new standalone TF2 Keras encoder ---\n",
      "--- Standalone Keras Encoder Built with FINAL Corrected Naming ---\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 32, 90)]          0         \n",
      "                                                                 \n",
      " cell_0 (Functional)         (None, 4096)              35045376  \n",
      "                                                                 \n",
      " mu (Dense)                  (None, 512)               2097664   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,143,040\n",
      "Trainable params: 37,143,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "--- Step 3: Starting weight transfer from TF1 session to TF2 model ---\n",
      "\n",
      "Processing layer: cell_0/bidirectional_rnn\n",
      "  - Successfully re-ordered, split, and transferred 6 weights for Bidirectional LSTM.\n",
      "\n",
      "Processing layer: mu\n",
      "  - Successfully transferred weights for Dense layer 'mu'.\n",
      "\n",
      "--- Step 4: Weight transfer complete. Saving the new Keras model. ---\n",
      "\n",
      "Successfully saved the new Keras model to: 'models/music_vae_encoder_keras'\n"
     ]
    }
   ],
   "source": [
    "# Use tensorflow.compat.v1 and disable V2 behavior\n",
    "\n",
    "print(\"--- Step 1: Loading original TF1-style MusicVAE model ---\")\n",
    "mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
    "BASE_DIR = \"models/download.magenta.tensorflow.org/models/music_vae\"\n",
    "checkpoint_path = BASE_DIR + '/checkpoints/mel_2bar_big.ckpt'\n",
    "mel_2bar = TrainedModel(mel_2bar_config, batch_size=4, checkpoint_dir_or_path=checkpoint_path)\n",
    "sess = mel_2bar._sess\n",
    "print(\"Original model loaded successfully.\")\n",
    "\n",
    "print(\"\\n--- Step 2: Building the new standalone TF2 Keras encoder ---\")\n",
    "encoder_input_shape = (mel_2bar_config.hparams.max_seq_len, mel_2bar_config.data_converter.input_depth)\n",
    "standalone_encoder = build_standalone_encoder(mel_2bar_config.hparams, input_shape=encoder_input_shape)\n",
    "\n",
    "print(\"\\n--- Step 3: Starting weight transfer from TF1 session to TF2 model ---\")\n",
    "tf1_variables = sess.graph.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "tf1_variable_names = [v.name for v in tf1_variables]\n",
    "tf1_variable_values = sess.run(tf1_variables)\n",
    "tf1_weights_map = dict(zip(tf1_variable_names, tf1_variable_values))\n",
    "\n",
    "# Iterate through the layers of our new Keras model to set their weights\n",
    "for layer in standalone_encoder.layers:\n",
    "    if layer.name == 'cell_0': # This is our Bidirectional sub-model\n",
    "        for sub_layer in layer.layers:\n",
    "            if isinstance(sub_layer, tf.keras.layers.Bidirectional):\n",
    "                print(f\"\\nProcessing layer: {layer.name}/{sub_layer.name}\")\n",
    "                \n",
    "                fw_kernel_name = 'encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel:0'\n",
    "                fw_bias_name = 'encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias:0'\n",
    "                bw_kernel_name = 'encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel:0'\n",
    "                bw_bias_name = 'encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias:0'\n",
    "                \n",
    "                try:\n",
    "                    # --- WEIGHT RE-ORDERING LOGIC ---\n",
    "                    def reorder_lstm_weights(kernel, bias, num_units):\n",
    "                        # TF1 format: [i, c, f, o] (input, cell, forget, output)\n",
    "                        # TF2 format: [i, f, c, o] (input, forget, cell, output)\n",
    "                        \n",
    "                        # Split into the 4 gate weights\n",
    "                        k_i, k_c, k_f, k_o = np.split(kernel, 4, axis=-1)\n",
    "                        b_i, b_c, b_f, b_o = np.split(bias, 4, axis=-1)\n",
    "                        \n",
    "                        # Re-assemble in TF2 order (swap c and f)\n",
    "                        reordered_kernel = np.concatenate([k_i, k_f, k_c, k_o], axis=-1)\n",
    "                        reordered_bias = np.concatenate([b_i, b_f, b_c, b_o], axis=-1)\n",
    "                        \n",
    "                        return reordered_kernel, reordered_bias\n",
    "\n",
    "                    # Get weights from checkpoint\n",
    "                    fw_kernel_tf1, fw_bias_tf1 = tf1_weights_map[fw_kernel_name], tf1_weights_map[fw_bias_name]\n",
    "                    bw_kernel_tf1, bw_bias_tf1 = tf1_weights_map[bw_kernel_name], tf1_weights_map[bw_bias_name]\n",
    "\n",
    "                    # Re-order weights to match Keras's expected format\n",
    "                    num_units = mel_2bar_config.hparams.enc_rnn_size[0]\n",
    "                    fw_kernel_tf2, fw_bias_tf2 = reorder_lstm_weights(fw_kernel_tf1, fw_bias_tf1, num_units)\n",
    "                    bw_kernel_tf2, bw_bias_tf2 = reorder_lstm_weights(bw_kernel_tf1, bw_bias_tf1, num_units)\n",
    "\n",
    "                    # Split the re-ordered kernels for Keras\n",
    "                    input_depth = mel_2bar_config.data_converter.input_depth\n",
    "                    fw_input_kernel, fw_recurrent_kernel = np.split(fw_kernel_tf2, [input_depth], axis=0)\n",
    "                    bw_input_kernel, bw_recurrent_kernel = np.split(bw_kernel_tf2, [input_depth], axis=0)\n",
    "                    \n",
    "                    # Assemble the final list of 6 weights\n",
    "                    keras_weights = [\n",
    "                        fw_input_kernel, fw_recurrent_kernel, fw_bias_tf2,\n",
    "                        bw_input_kernel, bw_recurrent_kernel, bw_bias_tf2\n",
    "                    ]\n",
    "                    \n",
    "                    sub_layer.set_weights(keras_weights)\n",
    "                    print(f\"  - Successfully re-ordered, split, and transferred 6 weights for Bidirectional LSTM.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  - FATAL ERROR: An exception occurred during weight transfer: {e}\")\n",
    "\n",
    "    if layer.name == 'mu' and isinstance(layer, tf.keras.layers.Dense):\n",
    "        # This part remains the same\n",
    "        print(f\"\\nProcessing layer: {layer.name}\")\n",
    "        kernel_name = f'encoder/mu/kernel:0'\n",
    "        bias_name = f'encoder/mu/bias:0'\n",
    "        try:\n",
    "            layer.set_weights([tf1_weights_map[kernel_name], tf1_weights_map[bias_name]])\n",
    "            print(f\"  - Successfully transferred weights for Dense layer 'mu'.\")\n",
    "        except KeyError as e:\n",
    "            print(f\"  - FATAL ERROR: Could not find weight {e} for 'mu' layer!\")\n",
    "\n",
    "print(\"\\n--- Step 4: Weight transfer complete. Saving the new Keras model. ---\")\n",
    "output_keras_model_path = 'models/music_vae_encoder_keras'\n",
    "tf.keras.models.save_model(standalone_encoder, output_keras_model_path)\n",
    "print(f\"\\nSuccessfully saved the new Keras model to: '{output_keras_model_path}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "332c01b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading original TF1-style MusicVAE model ---\n",
      "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n",
      "{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 1, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
      "INFO:tensorflow:\n",
      "Encoder Cells (bidirectional):\n",
      "  units: [2048]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [2048, 2048, 2048]\n",
      "\n",
      "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from models/download.magenta.tensorflow.org/models/music_vae/checkpoints/mel_2bar_big.ckpt\n",
      "Original model loaded.\n",
      "\n",
      "--- Step 2: Loading the new standalone Keras encoder ---\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "New Keras model loaded.\n",
      "\n",
      "--- Step 3: Generating a random input tensor ---\n",
      "Generated random input with shape: (1, 32, 90)\n",
      "\n",
      "--- Step 4: Running inference on both models ---\n",
      "Generated empty controls with shape: (1, 32, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 5: Comparing the outputs ---\n",
      "Original model's embedding (first 5 values): [-0.9633615  1.2745852  1.700005  -1.7129043 -1.2040325]\n",
      "New Keras model's embedding (first 5 values):  [-0.8934264  1.2289464  1.5655204 -1.4896607 -1.3244532]\n",
      "\n",
      "--- VERIFICATION RESULT ---\n",
      "❌ FAILURE: The embeddings do not match.\n",
      "   (Mean absolute difference: 0.09183776378631592)\n"
     ]
    }
   ],
   "source": [
    "# Use tensorflow.compat.v1 and disable V2 behavior for the original model\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. SETUP & MODEL LOADING\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"--- Step 1: Loading original TF1-style MusicVAE model ---\")\n",
    "mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
    "BASE_DIR = \"models/download.magenta.tensorflow.org/models/music_vae\"\n",
    "checkpoint_path = BASE_DIR + '/checkpoints/mel_2bar_big.ckpt'\n",
    "\n",
    "# Use a batch size of 1 for easier comparison\n",
    "BATCH_SIZE = 1\n",
    "mel_2bar = TrainedModel(mel_2bar_config, batch_size=BATCH_SIZE, checkpoint_dir_or_path=checkpoint_path)\n",
    "sess = mel_2bar._sess\n",
    "print(\"Original model loaded.\")\n",
    "\n",
    "print(\"\\n--- Step 2: Loading the new standalone Keras encoder ---\")\n",
    "keras_model_path = 'models/music_vae_encoder_keras'\n",
    "# We can load the Keras model using the modern API\n",
    "standalone_encoder = tf.keras.models.load_model(keras_model_path)\n",
    "print(\"New Keras model loaded.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. INFERENCE & COMPARISON\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- Step 3: Generating a random input tensor ---\")\n",
    "seq_len = mel_2bar_config.hparams.max_seq_len\n",
    "input_depth = mel_2bar_config.data_converter.input_depth\n",
    "control_depth = mel_2bar_config.data_converter.control_depth # This will be 0\n",
    "input_shape = (BATCH_SIZE, seq_len, input_depth)\n",
    "\n",
    "random_input = np.random.rand(*input_shape).astype(np.float32)\n",
    "print(f\"Generated random input with shape: {random_input.shape}\")\n",
    "\n",
    "print(\"\\n--- Step 4: Running inference on both models ---\")\n",
    "\n",
    "# --- Get embedding from the ORIGINAL TF1 model ---\n",
    "\n",
    "# ** THE FIX IS HERE **\n",
    "# Create an empty array for the `_controls` placeholder\n",
    "empty_controls = np.zeros((BATCH_SIZE, seq_len, control_depth), dtype=np.float32)\n",
    "print(f\"Generated empty controls with shape: {empty_controls.shape}\")\n",
    "\n",
    "# Add the empty controls to the feed_dict\n",
    "feed_dict = {\n",
    "    mel_2bar._inputs: random_input,\n",
    "    mel_2bar._inputs_length: [seq_len] * BATCH_SIZE,\n",
    "    mel_2bar._controls: empty_controls # Add the required empty placeholder value\n",
    "}\n",
    "# `_mu` is the tensor that holds the embedding\n",
    "original_embedding = sess.run(mel_2bar._mu, feed_dict)\n",
    "\n",
    "\n",
    "# --- Get embedding from the NEW Keras model ---\n",
    "keras_embedding = standalone_encoder.predict(random_input)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. VERIFICATION\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- Step 5: Comparing the outputs ---\")\n",
    "print(f\"Original model's embedding (first 5 values): {original_embedding[0, :5]}\")\n",
    "print(f\"New Keras model's embedding (first 5 values):  {keras_embedding[0, :5]}\")\n",
    "\n",
    "are_close = np.allclose(original_embedding, keras_embedding, atol=1e-6)\n",
    "\n",
    "print(\"\\n--- VERIFICATION RESULT ---\")\n",
    "if are_close:\n",
    "    print(\"✅ SUCCESS: The embeddings from both models are identical!\")\n",
    "    abs_diff = np.mean(np.abs(original_embedding - keras_embedding))\n",
    "    print(f\"   (Mean absolute difference: {abs_diff:.10f})\")\n",
    "else:\n",
    "    print(\"❌ FAILURE: The embeddings do not match.\")\n",
    "    abs_diff = np.mean(np.abs(original_embedding - keras_embedding))\n",
    "    print(f\"   (Mean absolute difference: {abs_diff})\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
