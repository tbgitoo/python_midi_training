{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c57f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# ======================================================================\n",
    "#  1. SETUP: Use a standard TF2 environment\n",
    "# ======================================================================\n",
    "\n",
    "# NO `tf.compat.v1.disable_eager_execution()` is needed.\n",
    "# We are in the default TF2 eager mode.\n",
    "\n",
    "SAVED_ENCODER_PATH = 'models/music_vae_encoder_keras'\n",
    "TFLITE_MODEL_PATH = 'models/music_vae_encoder_tf2.tflite'\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Eager execution enabled: {tf.executing_eagerly()}\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "#  2. LOAD: Load the Keras model using the modern API\n",
    "# ======================================================================\n",
    "\n",
    "print(f\"\\nLoading Keras model from: {SAVED_ENCODER_PATH}\")\n",
    "# tf.keras in TF2 can load models saved from the TF1-era Keras.\n",
    "try:\n",
    "    standalone_encoder = tf.keras.models.load_model(SAVED_ENCODER_PATH)\n",
    "    print(\"Model loaded successfully.\")\n",
    "    standalone_encoder.summary()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"This might happen if the model contains custom layers or legacy features not supported in TF2's loader.\")\n",
    "    # If this fails, you must fall back to the TF1 compatibility method.\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "#  3. CONVERT: Use the standard `TFLiteConverter`\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\nStarting TFLite conversion using the TF2 converter...\")\n",
    "\n",
    "# The `from_keras_model` method is the most direct and recommended approach.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(standalone_encoder)\n",
    "\n",
    "# --- APPLY THE FIX HERE ---\n",
    "# 1. Enable the \"Select TF Ops\" feature.\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TFLite native ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS     # Enable TF ops.\n",
    "]\n",
    "\n",
    "# 2. Disable the experimental flag that was causing the error.\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "# --- END OF FIX ---\n",
    "\n",
    "# (Optional but Recommended) Add optimizations.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Perform the conversion.\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "print(\"Conversion successful!\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "#  4. SAVE AND VERIFY\n",
    "# ======================================================================\n",
    "\n",
    "with open(TFLITE_MODEL_PATH, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"\\nSaved TFLite model to: {TFLITE_MODEL_PATH}\")\n",
    "\n",
    "# Verification step remains the same and is always a good idea.\n",
    "print(\"\\nVerifying the TFLite model...\")\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "tflite_output = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"TFLite model ran successfully!\")\n",
    "print(\"Sample output:\", tflite_output[0, :5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be81fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
