{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c4f858b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Keras model from: models/music_vae_decoder_keras\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Keras model loaded successfully.\n",
      "Located 'generate' signature.\n",
      "Signature inputs: ['z']\n",
      "Signature outputs: ['output_0']\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from model_def.decoder import MusicVAEDecoder, AutoregressiveStep\n",
    "\n",
    "# --- Configuration ---\n",
    "MODEL_DIR = \"models/music_vae_decoder_keras\"\n",
    "LATENT_DIM = 512\n",
    "SEQUENCE_LENGTH = 32 # The sequence length you used when saving the model\n",
    "\n",
    "# --- 1. Load the Keras SavedModel ---\n",
    "print(f\"Loading Keras model from: {MODEL_DIR}\")\n",
    "# Create the dictionary of custom objects\n",
    "custom_objects = {\n",
    "    \"MusicVAEDecoder\": MusicVAEDecoder,\n",
    "    \"AutoregressiveStep\": AutoregressiveStep\n",
    "}\n",
    "\n",
    "\n",
    "# This loads the entire model, including the architecture and the traced signatures.\n",
    "loaded_keras_model = tf.keras.models.load_model(MODEL_DIR,custom_objects=custom_objects)\n",
    "print(\"Keras model loaded successfully.\")\n",
    "\n",
    "# --- 2. Access the 'generate' signature ---\n",
    "# The signatures dictionary holds the pre-traced functions we saved.\n",
    "generate_signature = loaded_keras_model.signatures['generate']\n",
    "print(\"Located 'generate' signature.\")\n",
    "print(\"Signature inputs:\", list(generate_signature.structured_input_signature[1].keys()))\n",
    "print(\"Signature outputs:\", list(generate_signature.structured_outputs.keys()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6215a471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated random latent vector 'z' with shape: (1, 512)\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Create a random latent vector ---\n",
    "# We'll use a fixed seed to ensure this input is reproducible.\n",
    "np.random.seed(42)\n",
    "z_input = np.random.randn(1, LATENT_DIM).astype(np.float32)\n",
    "print(f\"\\nGenerated random latent vector 'z' with shape: {z_input.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b143d5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference with the Keras model...\n",
      "Inference complete.\n",
      "Keras model output logits shape: (1, 32, 90)\n",
      "[-0.21730028 -3.5196676  -1.7660146  -2.4989333  -2.6764984 ]\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Run inference ---\n",
    "print(\"Running inference with the Keras model...\")\n",
    "# The signature expects a TensorFlow constant.\n",
    "# The output is a dictionary, as defined by the signature's outputs.\n",
    "keras_output_dict = generate_signature(z=tf.constant(z_input))\n",
    "\n",
    "# The output key might be 'output_0' or a more descriptive name.\n",
    "# We inspect the dictionary keys to find the correct one.\n",
    "output_key = list(keras_output_dict.keys())[0]\n",
    "keras_logits = keras_output_dict[output_key].numpy()\n",
    "\n",
    "print(\"Inference complete.\")\n",
    "print(f\"Keras model output logits shape: {keras_logits.shape}\")\n",
    "\n",
    "print(keras_logits[0, 0, :5])\n",
    "\n",
    "#musicvae sequence [ 4.8953643  2.3632274 -6.4150443 -8.422484  -7.8997383]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3857286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "--- Step 1: Loading original TF1-style MusicVAE model ---\n",
      "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n",
      "{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 1, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
      "INFO:tensorflow:\n",
      "Encoder Cells (bidirectional):\n",
      "  units: [2048]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [2048, 2048, 2048]\n",
      "\n",
      "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
      "WARNING:tensorflow:From d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\models\\music_vae\\lstm_utils.py:94: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  tf.layers.dense(\n",
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\contrib\\rnn.py:749: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  self._kernel = self.add_variable(\n",
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\contrib\\rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  self._bias = self.add_variable(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\contrib\\rnn.py:463: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:437: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:342: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n",
      "INFO:tensorflow:Restoring parameters from models/download.magenta.tensorflow.org/models/music_vae/checkpoints/mel_2bar_big.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\models\\music_vae\\base_model.py:195: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  mu = tf.layers.dense(\n",
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\models\\music_vae\\base_model.py:200: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  sigma = tf.layers.dense(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model loaded.\n",
      "\n",
      "Logits shape from TF1 model: (32, 1, 90)\n",
      "\n",
      "Logits for the very first step (first 5 values):\n",
      "[ 4.8953643  2.3632274 -6.4150443 -8.422484  -7.8997383]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from magenta.models.music_vae import configs\n",
    "from magenta.models.music_vae.trained_model import TrainedModel # We need this class\n",
    "import os\n",
    "\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "LATENT_DIM = 512\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# --- Configuration ---\n",
    "MODEL_NAME = \"mel_2bar_big\"\n",
    "CHECKPOINT_DIR = \"models/download.magenta.tensorflow.org/models/music_vae/checkpoints\"\n",
    "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, f\"{MODEL_NAME}.ckpt\")\n",
    "\n",
    "# --- Correct parameters for 'mel_2bar_big' ---\n",
    "\n",
    "# Use tensorflow.compat.v1 and disable V2 behavior for the original model\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. SETUP & MODEL LOADING\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"--- Step 1: Loading original TF1-style MusicVAE model ---\")\n",
    "mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
    "BASE_DIR = \"models/download.magenta.tensorflow.org/models/music_vae\"\n",
    "checkpoint_path = BASE_DIR + '/checkpoints/mel_2bar_big.ckpt'\n",
    "\n",
    "# Use a batch size of 1 for easier comparison\n",
    "LATENT_DIM = mel_2bar_config.hparams.z_size\n",
    "SEQUENCE_LENGTH = 32 # Define the desired generation length\n",
    "BATCH_SIZE = 1\n",
    "VOCAB_SIZE = 90\n",
    "mel_2bar = TrainedModel(mel_2bar_config, batch_size=BATCH_SIZE, checkpoint_dir_or_path=checkpoint_path)\n",
    "print(\"Original model loaded.\")\n",
    "\n",
    "graph = mel_2bar._sess.graph\n",
    "\n",
    "# --- Use the exact names discovered from your debugging ---\n",
    "# The z placeholder with shape (1, 512)\n",
    "Z_PLACEHOLDER_NAME = 'Placeholder_1:0'\n",
    "\n",
    "# The output logits tensor from the sampling graph\n",
    "LOGITS_TENSOR_NAME = 'sample/decoder/rnn_output:0'\n",
    "\n",
    "\n",
    "\n",
    "model_blueprint = mel_2bar_config.model\n",
    "decoder_blueprint = model_blueprint.decoder\n",
    "\n",
    "    # Retrive the relevant elements of the graph\n",
    "temperature_placeholder = graph.get_tensor_by_name('Placeholder:0')\n",
    "z_placeholder = graph.get_tensor_by_name('Placeholder_1:0')\n",
    "inputs_placeholder = graph.get_tensor_by_name('Placeholder_2:0')\n",
    "controls_placeholder = graph.get_tensor_by_name('Placeholder_3:0')\n",
    "inputs_length_placeholder = graph.get_tensor_by_name('Placeholder_4:0')\n",
    "output_length_placeholder = graph.get_tensor_by_name('Placeholder_5:0') # The final placeholder\n",
    "logits_tensor = graph.get_tensor_by_name('decoder/TensorArrayStack_1/TensorArrayGatherV3:0')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Dummy inputs to satisfy the graph's requirements, based on your debugging\n",
    "dummy_inputs = np.zeros((BATCH_SIZE, SEQUENCE_LENGTH, VOCAB_SIZE), dtype=np.float32)\n",
    "dummy_inputs_length = np.array([SEQUENCE_LENGTH] * BATCH_SIZE, dtype=np.int32)\n",
    "dummy_controls = np.zeros((BATCH_SIZE, SEQUENCE_LENGTH, 0), dtype=np.float32)\n",
    "\n",
    "# Construct the full, correct feed dictionary\n",
    "feed_dict = {\n",
    "    temperature_placeholder: 0, # We don't need the temperature here other than as a dummy\n",
    "    z_placeholder: z_input,\n",
    "    inputs_placeholder: dummy_inputs,\n",
    "    inputs_length_placeholder: dummy_inputs_length,\n",
    "    controls_placeholder: dummy_controls,\n",
    "    output_length_placeholder: SEQUENCE_LENGTH # The final missing piece\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "logits_tf1 = mel_2bar._sess.run(\n",
    "    logits_tensor,\n",
    "    feed_dict=feed_dict\n",
    ")\n",
    "\n",
    "print(\"\\nLogits shape from TF1 model:\", logits_tf1.shape)\n",
    "\n",
    "print(\"\\nLogits for the very first step (first 5 values):\")\n",
    "print(logits_tf1[0, 0, :5])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Main Comparison Logic ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ec83def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.072735\n"
     ]
    }
   ],
   "source": [
    "musicvae_embeddings= logits_tf1[0,0,:]\n",
    "keras_embedding= keras_logits[0,0,:]\n",
    "\n",
    "dist_musicvae_vs_keras = np.linalg.norm(musicvae_embeddings - keras_embedding)\n",
    "print(dist_musicvae_vs_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1224b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is for debugging purposes. \n",
    "# If you want valid values for tf1, don't forget to include tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "def inspect_checkpoint(checkpoint_path):\n",
    "    \"\"\"\n",
    "    A helper function to print all variable names and their shapes in a checkpoint.\n",
    "    This is extremely useful for debugging name-related errors.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Inspecting variables in checkpoint: {checkpoint_path} ---\")\n",
    "    try:\n",
    "        reader = tf.train.load_checkpoint(checkpoint_path)\n",
    "        shape_map = reader.get_variable_to_shape_map()\n",
    "        for key in sorted(shape_map.keys()):\n",
    "            print(f\"Tensor name: {key}, shape: {shape_map[key]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read checkpoint: {e}\")\n",
    "    print(\"--------------------------------------------------------\\n\")\n",
    "\n",
    "MODEL_NAME = \"mel_2bar_big\"\n",
    "CHECKPOINT_DIR = \"models/download.magenta.tensorflow.org/models/music_vae/checkpoints\"\n",
    "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, f\"{MODEL_NAME}.ckpt\")\n",
    "\n",
    "inspect_checkpoint(CHECKPOINT_PATH)\n",
    "\n",
    "\n",
    "def get_tensor_names_from_graph(graph):\n",
    "    \"\"\"\n",
    "    A helper function to print all tensor names in a TensorFlow graph.\n",
    "    This helps identify the correct names to use when accessing tensors.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Inspecting tensors in the graph ---\")\n",
    "    for index in range(len(graph.get_operations())):\n",
    "        op = graph.get_operations()[index]\n",
    "        print(f\"Operation name: {op.name}\"+\"\\n\")\n",
    "        for tensor in op.values():\n",
    "            print(f\"Tensor name: {tensor.name}, shape: {tensor.shape}\"+\"\\n\")\n",
    "    print(\"--------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "get_tensor_names_from_graph(graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
