{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c973dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_def.decoder import MusicVAEDecoder, LATENT_DIM, OUTPUT_DEPTH, SEQUENCE_LENGTH, LSTM_UNITS, NUM_LAYERS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e3665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instance created.\n",
      "\n",
      "Manually building model layers...\n",
      "Built 'z_to_initial_state' layer.\n",
      "Built LSTM cell 0 with input dimension 602.\n",
      "Built LSTM cell 1 with input dimension 2048.\n",
      "Built LSTM cell 2 with input dimension 2048.\n",
      "Built 'output_projection' layer.\n",
      "\n",
      "All layers built successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 2. Instantiate our TF2 Keras decoder model with the correct number of layers.\n",
    "decoder = MusicVAEDecoder(\n",
    "    output_depth=OUTPUT_DEPTH,\n",
    "    lstm_units=LSTM_UNITS,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    sequence_length=SEQUENCE_LENGTH\n",
    ")\n",
    "print(\"Model instance created.\")\n",
    "\n",
    "# --- MANUALLY BUILD EACH LAYER WITH THE CORRECT INPUT SHAPE ---\n",
    "print(\"\\nManually building model layers...\")\n",
    "\n",
    "# 1. Build the initial dense layer. It takes `z` as input.\n",
    "decoder.z_to_initial_state.build(input_shape=(None, LATENT_DIM))\n",
    "print(f\"Built 'z_to_initial_state' layer.\")\n",
    "\n",
    "# 2. Build the LSTM cells. This is the most critical part.\n",
    "# The input to the *first* LSTM cell is the concatenation of the previous step's output (90) and z (512).\n",
    "first_lstm_input_dim = OUTPUT_DEPTH + LATENT_DIM # 90 + 512 = 602\n",
    "decoder.lstm_cells[0].build(input_shape=(None, first_lstm_input_dim))\n",
    "print(f\"Built LSTM cell 0 with input dimension {first_lstm_input_dim}.\")\n",
    "\n",
    "# The input to subsequent LSTM cells is the output of the previous cell.\n",
    "for i in range(1, len(decoder.lstm_cells)):\n",
    "    prev_cell_output_dim = decoder.lstm_cells[i-1].units\n",
    "    decoder.lstm_cells[i].build(input_shape=(None, prev_cell_output_dim))\n",
    "    print(f\"Built LSTM cell {i} with input dimension {prev_cell_output_dim}.\")\n",
    "\n",
    "# 3. Build the final output projection layer. It takes the output of the last LSTM cell.\n",
    "last_lstm_output_dim = decoder.lstm_cells[-1].units\n",
    "decoder.output_projection.build(input_shape=(None, last_lstm_output_dim))\n",
    "print(f\"Built 'output_projection' layer.\")\n",
    "\n",
    "print(\"\\nAll layers built successfully.\")\n",
    "# 4. Finally, indicate that the model is built.\n",
    "_ = decoder(z=tf.zeros((1, LATENT_DIM)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d4b87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Magenta weights into the built model...\n",
      "Loaded weights for 'z_to_initial_state' layer.\n",
      "Loaded weights for LSTM cell 0 from 'decoder/multi_rnn_cell/cell_0/lstm_cell/kernel'.\n",
      "Loaded weights for LSTM cell 1 from 'decoder/multi_rnn_cell/cell_1/lstm_cell/kernel'.\n",
      "Loaded weights for LSTM cell 2 from 'decoder/multi_rnn_cell/cell_2/lstm_cell/kernel'.\n",
      "Loaded weights for 'output_projection' layer.\n",
      "\n",
      "Successfully loaded all decoder weights from Magenta checkpoint!\n",
      "Weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Now, loading the weights will work ---\n",
    "print(\"\\nLoading Magenta weights into the built model...\")\n",
    "\n",
    "MODEL_NAME = \"mel_2bar_big\"\n",
    "CHECKPOINT_DIR = \"models/download.magenta.tensorflow.org/models/music_vae/checkpoints\"\n",
    "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, f\"{MODEL_NAME}.ckpt\")\n",
    "\n",
    "\n",
    "load_magenta_weights(decoder, CHECKPOINT_PATH) # This should now succeed\n",
    "print(\"Weights loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc5135fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concrete functions created successfully.\n",
      "INFO:tensorflow:Assets written to: models/music_vae_decoder_keras\\assets\n",
      "\n",
      "Model saved successfully to 'models/music_vae_decoder_keras'.\n"
     ]
    }
   ],
   "source": [
    "# This forces the creation of the `FuncGraph(name=reconstruct)`\n",
    "concrete_reconstruct = decoder.reconstruct.get_concrete_function()\n",
    "\n",
    "# This forces the creation of the `FuncGraph(name=generate)`\n",
    "concrete_generate = decoder.generate.get_concrete_function()\n",
    "\n",
    "print(\"Concrete functions created successfully.\")\n",
    "\n",
    "# --- Now, you can save the full model with signatures ---\n",
    "# Define the path for the saved model directory\n",
    "model_save_path = \"models/music_vae_decoder_keras\" \n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "decoder.save(model_save_path, signatures={\n",
    "    'reconstruct': concrete_reconstruct,\n",
    "    'generate': concrete_generate\n",
    "},save_format=\"tf\")\n",
    "print(f\"\\nModel saved successfully to '{model_save_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5739ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading original TF1-style MusicVAE model ---\n",
      "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n",
      "{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 1, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
      "INFO:tensorflow:\n",
      "Encoder Cells (bidirectional):\n",
      "  units: [2048]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [2048, 2048, 2048]\n",
      "\n",
      "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
      "WARNING:tensorflow:From d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\models\\music_vae\\lstm_utils.py:94: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  tf.layers.dense(\n",
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\contrib\\rnn.py:749: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  self._kernel = self.add_variable(\n",
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\contrib\\rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  self._bias = self.add_variable(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\contrib\\rnn.py:463: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:437: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:342: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\models\\music_vae\\base_model.py:195: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  mu = tf.layers.dense(\n",
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\models\\music_vae\\base_model.py:200: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  sigma = tf.layers.dense(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/download.magenta.tensorflow.org/models/music_vae/checkpoints/mel_2bar_big.ckpt\n",
      "Original model loaded.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"The name 'decoder/TensorArrayStack_1/TensorArrayGatherV3:0' refers to a Tensor which does not exist. The operation, 'decoder/TensorArrayStack_1/TensorArrayGatherV3', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m inputs_length_placeholder \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mget_tensor_by_name(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlaceholder_4:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     60\u001b[0m output_length_placeholder \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mget_tensor_by_name(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlaceholder_5:0\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# The final placeholder\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m logits_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensor_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdecoder/TensorArrayStack_1/TensorArrayGatherV3:0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     65\u001b[0m z_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(BATCH_SIZE, LATENT_DIM)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32md:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4188\u001b[0m, in \u001b[0;36mGraph.get_tensor_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   4186\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor names are strings (or similar), not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   4187\u001b[0m                   \u001b[38;5;28mtype\u001b[39m(name)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m-> 4188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_graph_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_operation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4012\u001b[0m, in \u001b[0;36mGraph.as_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   4009\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_as_graph_element_locked(obj, allow_tensor, allow_operation)\n\u001b[0;32m   4011\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 4012\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_graph_element_locked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_operation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4052\u001b[0m, in \u001b[0;36mGraph._as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   4050\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_name[op_name]\n\u001b[0;32m   4051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4052\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m refers to a Tensor which does not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4053\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexist. The operation, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, does not exist in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4054\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(name), \u001b[38;5;28mrepr\u001b[39m(op_name)))\n\u001b[0;32m   4055\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   4056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39moutputs[out_n]\n",
      "\u001b[1;31mKeyError\u001b[0m: \"The name 'decoder/TensorArrayStack_1/TensorArrayGatherV3:0' refers to a Tensor which does not exist. The operation, 'decoder/TensorArrayStack_1/TensorArrayGatherV3', does not exist in the graph.\""
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06da8bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m(z_np, sequence_length\u001b[38;5;241m=\u001b[39mSEQUENCE_LENGTH)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_sequence[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, :\u001b[38;5;241m5\u001b[39m][:\u001b[38;5;241m10\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'decoder' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d595dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "719d5f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inspecting variables in checkpoint: models/download.magenta.tensorflow.org/models/music_vae/checkpoints\\mel_2bar_big.ckpt ---\n",
      "Tensor name: beta1_power, shape: []\n",
      "Tensor name: beta2_power, shape: []\n",
      "Tensor name: decoder/multi_rnn_cell/cell_0/lstm_cell/bias, shape: [8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam, shape: [8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1, shape: [8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_0/lstm_cell/kernel, shape: [2650, 8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam, shape: [2650, 8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1, shape: [2650, 8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_1/lstm_cell/bias, shape: [8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_1/lstm_cell/bias/Adam, shape: [8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_1/lstm_cell/bias/Adam_1, shape: [8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_1/lstm_cell/kernel, shape: [4096, 8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam, shape: [4096, 8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam_1, shape: [4096, 8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_2/lstm_cell/bias, shape: [8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_2/lstm_cell/bias/Adam, shape: [8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_2/lstm_cell/bias/Adam_1, shape: [8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_2/lstm_cell/kernel, shape: [4096, 8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_2/lstm_cell/kernel/Adam, shape: [4096, 8192]\n",
      "Tensor name: decoder/multi_rnn_cell/cell_2/lstm_cell/kernel/Adam_1, shape: [4096, 8192]\n",
      "Tensor name: decoder/output_projection/bias, shape: [90]\n",
      "Tensor name: decoder/output_projection/bias/Adam, shape: [90]\n",
      "Tensor name: decoder/output_projection/bias/Adam_1, shape: [90]\n",
      "Tensor name: decoder/output_projection/kernel, shape: [2048, 90]\n",
      "Tensor name: decoder/output_projection/kernel/Adam, shape: [2048, 90]\n",
      "Tensor name: decoder/output_projection/kernel/Adam_1, shape: [2048, 90]\n",
      "Tensor name: decoder/z_to_initial_state/bias, shape: [12288]\n",
      "Tensor name: decoder/z_to_initial_state/bias/Adam, shape: [12288]\n",
      "Tensor name: decoder/z_to_initial_state/bias/Adam_1, shape: [12288]\n",
      "Tensor name: decoder/z_to_initial_state/kernel, shape: [512, 12288]\n",
      "Tensor name: decoder/z_to_initial_state/kernel/Adam, shape: [512, 12288]\n",
      "Tensor name: decoder/z_to_initial_state/kernel/Adam_1, shape: [512, 12288]\n",
      "Tensor name: encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias, shape: [8192]\n",
      "Tensor name: encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam, shape: [8192]\n",
      "Tensor name: encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1, shape: [8192]\n",
      "Tensor name: encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel, shape: [2138, 8192]\n",
      "Tensor name: encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam, shape: [2138, 8192]\n",
      "Tensor name: encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1, shape: [2138, 8192]\n",
      "Tensor name: encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias, shape: [8192]\n",
      "Tensor name: encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam, shape: [8192]\n",
      "Tensor name: encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1, shape: [8192]\n",
      "Tensor name: encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel, shape: [2138, 8192]\n",
      "Tensor name: encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam, shape: [2138, 8192]\n",
      "Tensor name: encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1, shape: [2138, 8192]\n",
      "Tensor name: encoder/mu/bias, shape: [512]\n",
      "Tensor name: encoder/mu/bias/Adam, shape: [512]\n",
      "Tensor name: encoder/mu/bias/Adam_1, shape: [512]\n",
      "Tensor name: encoder/mu/kernel, shape: [4096, 512]\n",
      "Tensor name: encoder/mu/kernel/Adam, shape: [4096, 512]\n",
      "Tensor name: encoder/mu/kernel/Adam_1, shape: [4096, 512]\n",
      "Tensor name: encoder/sigma/bias, shape: [512]\n",
      "Tensor name: encoder/sigma/bias/Adam, shape: [512]\n",
      "Tensor name: encoder/sigma/bias/Adam_1, shape: [512]\n",
      "Tensor name: encoder/sigma/kernel, shape: [4096, 512]\n",
      "Tensor name: encoder/sigma/kernel/Adam, shape: [4096, 512]\n",
      "Tensor name: encoder/sigma/kernel/Adam_1, shape: [4096, 512]\n",
      "Tensor name: global_step, shape: []\n",
      "--------------------------------------------------------\n",
      "\n",
      "\n",
      "--- Inspecting tensors in the graph ---\n",
      "--------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def inspect_checkpoint(checkpoint_path):\n",
    "    \"\"\"\n",
    "    A helper function to print all variable names and their shapes in a checkpoint.\n",
    "    This is extremely useful for debugging name-related errors.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Inspecting variables in checkpoint: {checkpoint_path} ---\")\n",
    "    try:\n",
    "        reader = tf.train.load_checkpoint(checkpoint_path)\n",
    "        shape_map = reader.get_variable_to_shape_map()\n",
    "        for key in sorted(shape_map.keys()):\n",
    "            print(f\"Tensor name: {key}, shape: {shape_map[key]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read checkpoint: {e}\")\n",
    "    print(\"--------------------------------------------------------\\n\")\n",
    "\n",
    "MODEL_NAME = \"mel_2bar_big\"\n",
    "CHECKPOINT_DIR = \"models/download.magenta.tensorflow.org/models/music_vae/checkpoints\"\n",
    "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, f\"{MODEL_NAME}.ckpt\")\n",
    "\n",
    "inspect_checkpoint(CHECKPOINT_PATH)\n",
    "\n",
    "\n",
    "def get_tensor_names_from_graph(graph):\n",
    "    \"\"\"\n",
    "    A helper function to print all tensor names in a TensorFlow graph.\n",
    "    This helps identify the correct names to use when accessing tensors.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Inspecting tensors in the graph ---\")\n",
    "    for index in range(len(graph.get_operations())):\n",
    "        op = graph.get_operations()[index]\n",
    "        print(f\"Operation name: {op.name}\"+\"\\n\")\n",
    "        for tensor in op.values():\n",
    "            print(f\"Tensor name: {tensor.name}, shape: {tensor.shape}\"+\"\\n\")\n",
    "    print(\"--------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "get_tensor_names_from_graph(tf.compat.v1.get_default_graph())\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
