{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c973dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_def.decoder import MusicVAEDecoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e26e3665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instance created.\n",
      "\n",
      "Manually building model layers...\n",
      "Built 'z_to_initial_state' layer.\n",
      "Built LSTM cell 0 with input dimension 602.\n",
      "Built LSTM cell 1 with input dimension 2048.\n",
      "Built LSTM cell 2 with input dimension 2048.\n",
      "Built 'output_projection' layer.\n",
      "\n",
      "All layers built successfully.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# 2. Instantiate our TF2 Keras decoder model with the correct number of layers.\n",
    "decoder = MusicVAEDecoder()\n",
    "print(\"Model instance created.\")\n",
    "\n",
    "# --- MANUALLY BUILD EACH LAYER WITH THE CORRECT INPUT SHAPE ---\n",
    "print(\"\\nManually building model layers...\")\n",
    "\n",
    "# 1. Build the initial dense layer. It takes `z` as input.\n",
    "decoder.z_to_initial_state.build(input_shape=(None, decoder.get_config()[\"latent_dim\"]))\n",
    "print(f\"Built 'z_to_initial_state' layer.\")\n",
    "\n",
    "# 2. Build the LSTM cells. This is the most critical part.\n",
    "# The input to the *first* LSTM cell is the concatenation of the previous step's output (90) and z (512).\n",
    "first_lstm_input_dim = decoder.get_config()[\"output_depth\"]+decoder.get_config()[\"latent_dim\"] # 90 + 512 = 602\n",
    "decoder.lstm_cells[0].build(input_shape=(None, first_lstm_input_dim))\n",
    "print(f\"Built LSTM cell 0 with input dimension {first_lstm_input_dim}.\")\n",
    "\n",
    "# The input to subsequent LSTM cells is the output of the previous cell.\n",
    "for i in range(1, len(decoder.lstm_cells)):\n",
    "    prev_cell_output_dim = decoder.lstm_cells[i-1].units\n",
    "    decoder.lstm_cells[i].build(input_shape=(None, prev_cell_output_dim))\n",
    "    print(f\"Built LSTM cell {i} with input dimension {prev_cell_output_dim}.\")\n",
    "\n",
    "# 3. Build the final output projection layer. It takes the output of the last LSTM cell.\n",
    "last_lstm_output_dim = decoder.lstm_cells[-1].units\n",
    "decoder.output_projection.build(input_shape=(None, last_lstm_output_dim))\n",
    "print(f\"Built 'output_projection' layer.\")\n",
    "\n",
    "print(\"\\nAll layers built successfully.\")\n",
    "\n",
    "# Get the model's configuration\n",
    "config = decoder.get_config()\n",
    "batch_size = 1 # Dummy batch size for building\n",
    "\n",
    "# Create dummy tensors with the correct shapes\n",
    "dummy_z = tf.zeros((batch_size, config[\"latent_dim\"]))\n",
    "dummy_sequence = tf.zeros((batch_size, config[\"sequence_length\"], config[\"output_depth\"]))\n",
    "\n",
    "# 4. Finally, Build the model by passing the inputs as a tuple\n",
    "_ = decoder((dummy_z, dummy_sequence))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9d4b87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Magenta weights into the built model...\n",
      "Loaded weights for 'z_to_initial_state' layer.\n",
      "Loaded weights for LSTM cell 0 from 'decoder/multi_rnn_cell/cell_0/lstm_cell/kernel'.\n",
      "Loaded weights for LSTM cell 1 from 'decoder/multi_rnn_cell/cell_1/lstm_cell/kernel'.\n",
      "Loaded weights for LSTM cell 2 from 'decoder/multi_rnn_cell/cell_2/lstm_cell/kernel'.\n",
      "Loaded weights for 'output_projection' layer.\n",
      "\n",
      "Successfully loaded all decoder weights from Magenta checkpoint!\n",
      "Weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from model_def.decoder import load_magenta_weights\n",
    "import os\n",
    "\n",
    "# --- Now, loading the weights will work ---\n",
    "print(\"\\nLoading Magenta weights into the built model...\")\n",
    "\n",
    "MODEL_NAME = \"mel_2bar_big\"\n",
    "CHECKPOINT_DIR = \"models/download.magenta.tensorflow.org/models/music_vae/checkpoints\"\n",
    "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, f\"{MODEL_NAME}.ckpt\")\n",
    "\n",
    "\n",
    "load_magenta_weights(decoder, CHECKPOINT_PATH) # This should now succeed\n",
    "print(\"Weights loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc5135fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating concrete functions for model signatures...\n",
      "Concrete functions created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as z_to_initial_state_layer_call_fn, z_to_initial_state_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/music_vae_decoder_keras\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/music_vae_decoder_keras\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved successfully to 'models/music_vae_decoder_keras'.\n"
     ]
    }
   ],
   "source": [
    "# Now, save the model with the correct weights and signatures.\n",
    "print(\"\\nCreating concrete functions for model signatures...\")\n",
    "# --- Create concrete functions for the signatures ---\n",
    "\n",
    "# This forces the creation of the `FuncGraph(name=reconstruct)`\n",
    "concrete_reconstruct = decoder.reconstruct.get_concrete_function()\n",
    "\n",
    "# This forces the creation of the `FuncGraph(name=generate)`\n",
    "concrete_generate = decoder.generate.get_concrete_function()\n",
    "\n",
    "print(\"Concrete functions created successfully.\")\n",
    "\n",
    "# --- Now, you can save the full model with signatures ---\n",
    "# Define the path for the saved model directory\n",
    "model_save_path = \"models/music_vae_decoder_keras\" \n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "decoder.save(model_save_path, signatures={\n",
    "    'reconstruct': concrete_reconstruct,\n",
    "    'generate': concrete_generate\n",
    "},save_format=\"tf\")\n",
    "print(f\"\\nModel saved successfully to '{model_save_path}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
