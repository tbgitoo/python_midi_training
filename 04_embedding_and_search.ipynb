{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fca81c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries and loading the trained model\n",
      "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n",
      "{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
      "INFO:tensorflow:\n",
      "Encoder Cells (bidirectional):\n",
      "  units: [2048]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [2048, 2048, 2048]\n",
      "\n",
      "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\models\\music_vae\\lstm_utils.py:94: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  tf.layers.dense(\n",
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\contrib\\rnn.py:749: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  self._kernel = self.add_variable(\n",
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\contrib\\rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  self._bias = self.add_variable(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/download.magenta.tensorflow.org/models/music_vae/checkpoints/mel_2bar_big.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\models\\music_vae\\base_model.py:195: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  mu = tf.layers.dense(\n",
      "d:\\Users\\thoma\\Documents\\git\\python_midi_training\\.venv\\lib\\site-packages\\magenta\\models\\music_vae\\base_model.py:200: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  sigma = tf.layers.dense(\n"
     ]
    }
   ],
   "source": [
    "print('Importing libraries and loading the trained model')\n",
    "import magenta.music as mm\n",
    "import note_seq\n",
    "from note_seq import sequences_lib\n",
    "from note_seq.protobuf import music_pb2\n",
    "from magenta.models.music_vae import configs\n",
    "from magenta.models.music_vae.trained_model import TrainedModel\n",
    "from magenta.models.music_vae.trained_model import NoExtractedExamplesError\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "import random\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import faiss  # You'll need to install this: pip install faiss-cpu\n",
    "\n",
    "\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
    "\n",
    "BASE_DIR=\"models/download.magenta.tensorflow.org/models/music_vae\"\n",
    "mel_2bar = TrainedModel(mel_2bar_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/mel_2bar_big.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc13c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DB_PATH = os.path.join('data_sets', 'midi_embeddings.db')\n",
    "FAISS_INDEX_PATH = os.path.join('data_sets', 'midi_embeddings.index')\n",
    "MELODY_DIR = os.path.join('data_sets', 'lmd_melodies') # Directory of extracted melodies\n",
    "EMBEDDING_DIM = 512 # The dimension of your MusicVAE embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0c2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pitch_range(ns, min_pitch=36, max_pitch=84):\n",
    "    \"\"\"Removes notes outside the specified MIDI pitch range.\"\"\"\n",
    "    valid_notes = [n for n in ns.notes if min_pitch <= n.pitch <= max_pitch]   \n",
    "    del ns.notes[:]\n",
    "    ns.notes.extend(valid_notes)   \n",
    "    return ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d277349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions (from previous iterations, still useful for cleaning) ---\n",
    "def make_monophonic(ns,steps_per_quarter=4):\n",
    "    \"\"\"Reduces a NoteSequence to be monophonic by picking the highest note at each step.\"\"\"\n",
    "    if not ns.notes:\n",
    "        return ns\n",
    "    quantized_ns = sequences_lib.quantize_note_sequence(ns, steps_per_quarter)    \n",
    "    notes_by_step = {}\n",
    "    for note in quantized_ns.notes:\n",
    "        # Use quantized_start_step for already quantized sequences\n",
    "        if note.quantized_start_step not in notes_by_step:\n",
    "            notes_by_step[note.quantized_start_step] = []\n",
    "        notes_by_step[note.quantized_start_step].append(note)\n",
    "    monophonic_notes = []\n",
    "    for step in sorted(notes_by_step.keys()):\n",
    "        notes_at_step = notes_by_step[step]\n",
    "        # If multiple notes at a step, pick the highest pitch\n",
    "        highest_note = max(notes_at_step, key=lambda n: n.pitch)\n",
    "        monophonic_notes.append(highest_note)\n",
    "    del ns.notes[:]\n",
    "    ns.notes.extend(monophonic_notes)\n",
    "    return ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0adaf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_chunk_notes_to_grid(unquantized_chunk, steps_per_quarter):\n",
    "    \"\"\"\n",
    "    Creates a new, unquantized NoteSequence with notes snapped to a grid.\n",
    "    This is the key function. It takes a time-based chunk, finds the ideal\n",
    "    quantized steps for its notes, and then creates a *new* unquantized\n",
    "    sequence where the note start/end times correspond perfectly to those steps.\n",
    "    Args:\n",
    "      unquantized_chunk: The unquantized NoteSequence chunk.\n",
    "      steps_per_quarter: The quantization resolution.\n",
    "    Returns:\n",
    "      A new, unquantized NoteSequence with grid-aligned note timings.\n",
    "    \"\"\"\n",
    "    # 1. Quantize the chunk to determine the ideal grid steps for each note.\n",
    "    try:\n",
    "        quantized_temp_chunk = note_seq.quantize_note_sequence(\n",
    "            unquantized_chunk, steps_per_quarter)\n",
    "    except note_seq.BadTimeSignatureError:\n",
    "        return None # Cannot process this chunk\n",
    "    qpm = unquantized_chunk.tempos[0].qpm if unquantized_chunk.tempos else 120.0\n",
    "    seconds_per_quarter = 60.0 / qpm\n",
    "    # 2. Create a new, empty, unquantized sequence to be the output.\n",
    "    grid_aligned_ns = music_pb2.NoteSequence()\n",
    "    grid_aligned_ns.tempos.add().qpm = qpm\n",
    "    grid_aligned_ns.ticks_per_quarter = unquantized_chunk.ticks_per_quarter\n",
    "    # 3. For each note in the quantized version, create a new note in our\n",
    "    #    output sequence with timings calculated from the quantized steps.\n",
    "    for q_note in quantized_temp_chunk.notes:\n",
    "        new_note = grid_aligned_ns.notes.add()\n",
    "        new_note.pitch = q_note.pitch\n",
    "        new_note.velocity = q_note.velocity\n",
    "        new_note.instrument = q_note.instrument\n",
    "        new_note.program = q_note.program\n",
    "        # Convert quantized steps back into precise seconds\n",
    "        start_quarters = q_note.quantized_start_step / steps_per_quarter\n",
    "        end_quarters = q_note.quantized_end_step / steps_per_quarter\n",
    "        new_note.start_time = start_quarters * seconds_per_quarter\n",
    "        new_note.end_time = end_quarters * seconds_per_quarter\n",
    "    # Set the total time of the new sequence.\n",
    "    total_quarters = quantized_temp_chunk.total_quantized_steps / steps_per_quarter\n",
    "    grid_aligned_ns.total_time = total_quarters * seconds_per_quarter\n",
    "    return grid_aligned_ns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a6adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_program_for_all_notes(note_sequence, program_number=0):\n",
    "    \"\"\"\n",
    "    Resets the instrument program for every note in a NoteSequence.\n",
    "    Args:\n",
    "      note_sequence: The note_seq.NoteSequence object to modify.\n",
    "      program_number: The integer program number to set for all notes.\n",
    "                      Defaults to 0 (Acoustic Grand Piano).\n",
    "    Returns:\n",
    "      The modified NoteSequence.\n",
    "    \"\"\"\n",
    "    for note in note_sequence.notes:\n",
    "        note.program = program_number\n",
    "    return note_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9aa42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sequence was split into 54 slices.\n",
      "The last quantized step of the first slice is: 0\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 48.0\n",
      "  end_time_offset: 168.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 52.0\n",
      "  end_time_offset: 164.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 56.0\n",
      "  end_time_offset: 160.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 60.0\n",
      "  end_time_offset: 156.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 64.0\n",
      "  end_time_offset: 152.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 68.0\n",
      "  end_time_offset: 148.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 72.0\n",
      "  end_time_offset: 144.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 76.0\n",
      "  end_time_offset: 140.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 80.0\n",
      "  end_time_offset: 136.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 84.0\n",
      "  end_time_offset: 132.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 88.0\n",
      "  end_time_offset: 128.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 92.0\n",
      "  end_time_offset: 124.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 136.0\n",
      "  end_time_offset: 80.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 140.0\n",
      "  end_time_offset: 76.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 144.0\n",
      "  end_time_offset: 72.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 148.0\n",
      "  end_time_offset: 68.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 152.0\n",
      "  end_time_offset: 64.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 156.0\n",
      "  end_time_offset: 60.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 160.0\n",
      "  end_time_offset: 56.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 164.0\n",
      "  end_time_offset: 52.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 168.0\n",
      "  end_time_offset: 48.0\n",
      "}\n",
      "\n",
      "Skipping chunk due to error: No examples extracted from NoteSequence: ticks_per_quarter: 220\n",
      "tempos {\n",
      "  qpm: 120.0\n",
      "}\n",
      "subsequence_info {\n",
      "  start_time_offset: 172.0\n",
      "  end_time_offset: 44.0\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. Load the MIDI file (unquantized) ---\n",
    "# Assume 'midi_ns' is your full NoteSequence object\n",
    "# midi_ns = note_seq.midi_file_to_note_sequence(full_path)\n",
    "\n",
    "# --- 3. Extract fixed-length, quantized chunks using sequences_lib.extract_subsequences ---\n",
    "# This function expects an UNQUANTIZED sequence and will internally quantize it\n",
    "# to extract segments of the specified number of steps.\n",
    "num_steps_per_chunk = config.hparams.max_seq_len  # This will be 32 for mel_2bar\n",
    "steps_per_quarter = config.data_converter._steps_per_quarter # This is needed by extract_subsequences internally\n",
    "\n",
    "# --- 2. Load the MIDI file (unquantized) ---\n",
    "full_path = 'data_sets/lmd_melodies/A/A/A/TRAAAGR128F425B14B/1d9d16a9da90c090809c153754823c2b.mid'\n",
    "midi_ns = note_seq.midi_file_to_note_sequence(full_path)\n",
    "cleaned_quantized_list = []\n",
    "cleaned_ms = make_monophonic(midi_ns)\n",
    "cleaned_ms = snap_chunk_notes_to_grid(cleaned_ms, steps_per_quarter)\n",
    "cleaned_ms = set_program_for_all_notes(cleaned_ms, program_number=0)\n",
    "qpm = cleaned_ms.tempos[0].qpm if cleaned_ms.tempos else 120.0\n",
    "seconds_per_quarter = 60.0 / qpm\n",
    "seconds_per_step = seconds_per_quarter / steps_per_quarter\n",
    "hop_size_in_seconds = num_steps_per_chunk * seconds_per_step # 32 / 4 = 8.0 seconds\n",
    "if cleaned_ms.notes:\n",
    "   slices = sequences_lib.split_note_sequence(\n",
    "        note_sequence=cleaned_ms,\n",
    "        hop_size_seconds=hop_size_in_seconds  \n",
    ")\n",
    "\n",
    "print(f\"The sequence was split into {len(slices)} slices.\")\n",
    "\n",
    "# You can now work with the 'slices' list, where each item is a 32-step NoteSequence.\n",
    "if slices:\n",
    "    print(f\"The last quantized step of the first slice is: {slices[0].total_quantized_steps}\")\n",
    "    for chunk in slices:\n",
    "        cleaned_quantized_list.append(chunk)\n",
    "else:\n",
    "    print(f\"Melody became empty after cleaning, skipping.\")\n",
    "embeddings=[]\n",
    "for chunk in cleaned_quantized_list:\n",
    "    try:\n",
    "        embedding = mel_2bar.encode([chunk])\n",
    "        embeddings.append(embedding)\n",
    "    except NoExtractedExamplesError as e:\n",
    "        print(f\"Skipping chunk due to error: {e}\")\n",
    "        continue\n",
    "print(f\"Generated {len(embeddings)} embeddings.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75356e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
