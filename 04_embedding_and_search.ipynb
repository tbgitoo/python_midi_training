{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca81c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries and loading the trained model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n",
      "{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
      "INFO:tensorflow:\n",
      "Encoder Cells (bidirectional):\n",
      "  units: [2048]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [2048, 2048, 2048]\n",
      "\n",
      "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from models/download.magenta.tensorflow.org/models/music_vae/checkpoints/mel_2bar_big.ckpt\n"
     ]
    }
   ],
   "source": [
    "print('Importing libraries and loading the trained model')\n",
    "import magenta.music as mm\n",
    "import note_seq\n",
    "from note_seq import sequences_lib\n",
    "from note_seq.protobuf import music_pb2\n",
    "from magenta.models.music_vae import configs\n",
    "from magenta.models.music_vae.trained_model import TrainedModel\n",
    "from magenta.models.music_vae.trained_model import NoExtractedExamplesError\n",
    "from magenta.models.music_vae.trained_model import MultipleExtractedExamplesError\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "import random\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import faiss  # You'll need to install this: pip install faiss-cpu\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
    "\n",
    "BASE_DIR=\"models/download.magenta.tensorflow.org/models/music_vae\"\n",
    "mel_2bar = TrainedModel(mel_2bar_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/mel_2bar_big.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc13c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DB_PATH = os.path.join('data_sets', 'midi_embeddings.db')\n",
    "FAISS_INDEX_PATH = os.path.join('data_sets', 'midi_embeddings.index')\n",
    "MELODY_DIR = os.path.join('data_sets', 'lmd_melodies') # Directory of extracted melodies\n",
    "EMBEDDING_DIM = 512 # The dimension of your MusicVAE embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0c2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pitch_range(ns, min_pitch=36, max_pitch=84):\n",
    "    \"\"\"Removes notes outside the specified MIDI pitch range.\"\"\"\n",
    "    valid_notes = [n for n in ns.notes if min_pitch <= n.pitch <= max_pitch]   \n",
    "    del ns.notes[:]\n",
    "    ns.notes.extend(valid_notes)   \n",
    "    return ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d277349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions (from previous iterations, still useful for cleaning) ---\n",
    "def make_monophonic(ns,steps_per_quarter=4):\n",
    "    \"\"\"Reduces a NoteSequence to be monophonic by picking the highest note at each step.\"\"\"\n",
    "    if not ns.notes:\n",
    "        return ns\n",
    "    quantized_ns = sequences_lib.quantize_note_sequence(ns, steps_per_quarter)    \n",
    "    notes_by_step = {}\n",
    "    for note in quantized_ns.notes:\n",
    "        # Use quantized_start_step for already quantized sequences\n",
    "        if note.quantized_start_step not in notes_by_step:\n",
    "            notes_by_step[note.quantized_start_step] = []\n",
    "        notes_by_step[note.quantized_start_step].append(note)\n",
    "    monophonic_notes = []\n",
    "    for step in sorted(notes_by_step.keys()):\n",
    "        notes_at_step = notes_by_step[step]\n",
    "        # If multiple notes at a step, pick the highest pitch\n",
    "        highest_note = max(notes_at_step, key=lambda n: n.pitch)\n",
    "        monophonic_notes.append(highest_note)\n",
    "    del ns.notes[:]\n",
    "    ns.notes.extend(monophonic_notes)\n",
    "    return ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0adaf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_chunk_notes_to_grid(unquantized_chunk, steps_per_quarter):\n",
    "    \"\"\"\n",
    "    Creates a new, unquantized NoteSequence with notes snapped to a grid.\n",
    "    This is the key function. It takes a time-based chunk, finds the ideal\n",
    "    quantized steps for its notes, and then creates a *new* unquantized\n",
    "    sequence where the note start/end times correspond perfectly to those steps.\n",
    "    Args:\n",
    "      unquantized_chunk: The unquantized NoteSequence chunk.\n",
    "      steps_per_quarter: The quantization resolution.\n",
    "    Returns:\n",
    "      A new, unquantized NoteSequence with grid-aligned note timings.\n",
    "    \"\"\"\n",
    "    # 1. Quantize the chunk to determine the ideal grid steps for each note.\n",
    "    try:\n",
    "        quantized_temp_chunk = note_seq.quantize_note_sequence(\n",
    "            unquantized_chunk, steps_per_quarter)\n",
    "    except note_seq.BadTimeSignatureError:\n",
    "        return None # Cannot process this chunk\n",
    "    qpm = unquantized_chunk.tempos[0].qpm if unquantized_chunk.tempos else 120.0\n",
    "    seconds_per_quarter = 60.0 / qpm\n",
    "    # 2. Create a new, empty, unquantized sequence to be the output.\n",
    "    grid_aligned_ns = music_pb2.NoteSequence()\n",
    "    grid_aligned_ns.tempos.add().qpm = qpm\n",
    "    grid_aligned_ns.ticks_per_quarter = unquantized_chunk.ticks_per_quarter\n",
    "    # 3. For each note in the quantized version, create a new note in our\n",
    "    #    output sequence with timings calculated from the quantized steps.\n",
    "    for q_note in quantized_temp_chunk.notes:\n",
    "        new_note = grid_aligned_ns.notes.add()\n",
    "        new_note.pitch = q_note.pitch\n",
    "        new_note.velocity = q_note.velocity\n",
    "        new_note.instrument = q_note.instrument\n",
    "        new_note.program = q_note.program\n",
    "        # Convert quantized steps back into precise seconds\n",
    "        start_quarters = q_note.quantized_start_step / steps_per_quarter\n",
    "        end_quarters = q_note.quantized_end_step / steps_per_quarter\n",
    "        new_note.start_time = start_quarters * seconds_per_quarter\n",
    "        new_note.end_time = end_quarters * seconds_per_quarter\n",
    "    # Set the total time of the new sequence.\n",
    "    total_quarters = quantized_temp_chunk.total_quantized_steps / steps_per_quarter\n",
    "    grid_aligned_ns.total_time = total_quarters * seconds_per_quarter\n",
    "    return grid_aligned_ns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a6adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_program_for_all_notes(note_sequence, program_number=0):\n",
    "    \"\"\"\n",
    "    Resets the instrument program for every note in a NoteSequence.\n",
    "    Args:\n",
    "      note_sequence: The note_seq.NoteSequence object to modify.\n",
    "      program_number: The integer program number to set for all notes.\n",
    "                      Defaults to 0 (Acoustic Grand Piano).\n",
    "    Returns:\n",
    "      The modified NoteSequence.\n",
    "    \"\"\"\n",
    "    for note in note_sequence.notes:\n",
    "        note.program = program_number\n",
    "    return note_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e152523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_tempo_from_notes(\n",
    "    note_sequence: music_pb2.NoteSequence,\n",
    "    min_bpm: float = 60.0,\n",
    "    max_bpm: float = 240.0,\n",
    "    prior_bpm: float = 120.0\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Estimates the tempo of an unquantized NoteSequence by analyzing note onsets.\n",
    "\n",
    "    Args:\n",
    "        note_sequence: An unquantized NoteSequence object.\n",
    "        min_bpm: The minimum plausible tempo to consider.\n",
    "        max_bpm: The maximum plausible tempo to consider.\n",
    "        prior_bpm: The tempo to prefer (e.g., 120 BPM). The algorithm will favor\n",
    "                   candidates closer to this value.\n",
    "\n",
    "    Returns:\n",
    "        The estimated tempo in beats per minute (BPM). Returns prior_bpm if\n",
    "        not enough notes are present to make a guess.\n",
    "    \"\"\"\n",
    "    # 1. Extract unique, sorted note onset times\n",
    "    onsets = sorted(list(set(note.start_time for note in note_sequence.notes)))\n",
    "\n",
    "    if len(onsets) < 3:  # Need a reasonable number of notes for a good guess\n",
    "        print(\"Warning: Too few notes to reliably estimate tempo. Returning prior.\")\n",
    "        bpm=prior_bpm\n",
    "        if note_sequence.tempos:\n",
    "            bpm = note_sequence.tempos[0].qpm\n",
    "        return bpm\n",
    "\n",
    "    # 2. Calculate Inter-Onset Intervals (IOIs)\n",
    "    iois = np.diff(onsets)\n",
    "    if len(iois) == 0:\n",
    "        bpm=prior_bpm\n",
    "        if note_sequence.tempos:\n",
    "            bpm = note_sequence.tempos[0].qpm\n",
    "        return bpm\n",
    "\n",
    "    # 3. Build a histogram of IOIs to find the most common intervals\n",
    "    # We use a small bin size to capture fine timing details\n",
    "    hist, bin_edges = np.histogram(iois, bins=np.arange(0, 5, 0.01), density=False)\n",
    "    \n",
    "    # Find peaks in the histogram. These are our primary rhythmic intervals.\n",
    "    # A simple way is to get the top N bins.\n",
    "    peak_indices = np.argsort(hist)[-10:] # Get indices of 10 strongest peaks\n",
    "    \n",
    "    tempo_candidates = defaultdict(float)\n",
    "\n",
    "    # 4. Generate and score tempo candidates from histogram peaks\n",
    "    for i in peak_indices:\n",
    "        if hist[i] < 2: # Ignore insignificant peaks\n",
    "            continue\n",
    "            \n",
    "        # The time (in seconds) corresponding to this peak\n",
    "        interval = bin_edges[i]\n",
    "        \n",
    "        # This interval could be a quarter note, eighth note, etc.\n",
    "        # Generate hypotheses based on this interval.\n",
    "        for multiple in [0.25, 0.33, 0.5, 1, 2, 3, 4]:\n",
    "            potential_beat_duration = interval * multiple\n",
    "            if potential_beat_duration == 0:\n",
    "                continue\n",
    "            \n",
    "            tempo = 60.0 / potential_beat_duration\n",
    "            \n",
    "            if min_bpm <= tempo <= max_bpm:\n",
    "                # 5. Score the candidate\n",
    "                # Score part 1: Rhythmic Strength (how strong was the peak?)\n",
    "                strength_score = hist[i]\n",
    "                \n",
    "                # Score part 2: Proximity to prior_bpm (Gaussian score)\n",
    "                # This gives a high score if tempo is near prior_bpm\n",
    "                proximity_score = np.exp(-0.5 * ((tempo - prior_bpm) / 20.0)**2)\n",
    "                \n",
    "                # Combine scores and add to any existing score for this tempo\n",
    "                combined_score = strength_score * proximity_score\n",
    "                tempo_candidates[tempo] += combined_score\n",
    "\n",
    "    if not tempo_candidates:\n",
    "        print(\"Warning: Could not find any valid tempo candidates. Returning prior.\")\n",
    "        bpm=prior_bpm\n",
    "        if note_sequence.tempos:\n",
    "            bpm = note_sequence.tempos[0].qpm\n",
    "        return bpm\n",
    "\n",
    "    # 6. Return the tempo with the highest score\n",
    "    best_tempo = max(tempo_candidates, key=tempo_candidates.get)\n",
    "    return best_tempo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9aa42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_for_song(track_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Finds all MIDI files for a given track_id, generates embeddings for each,\n",
    "    and returns them in a dictionary.\n",
    "\n",
    "    Args:\n",
    "        track_id (str): The ID of the track, e.g., \"TRAAAGR128F425B14B\".\n",
    "        root_path (str): The root path of the repository.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are MIDI filenames and values are lists of\n",
    "        numpy array embeddings generated from that MIDI file.\n",
    "        Returns an empty dictionary if the folder is not found or contains no MIDI files.\n",
    "    \"\"\"\n",
    "    # 1. Construct the folder path from the track_id\n",
    "    # e.g., 'data_sets/lmd_melodies/A/A/A/TRAAAGR128F425B14B'\n",
    "    if len(track_id) < 5:\n",
    "        print(f\"Error: track_id '{track_id}' is too short to build a path.\")\n",
    "        return {}\n",
    "        \n",
    "    song_folder_path = os.path.join(\n",
    "        'data_sets',\n",
    "        'lmd_melodies',\n",
    "        track_id[2],\n",
    "        track_id[3],\n",
    "        track_id[4],\n",
    "        track_id\n",
    "    )\n",
    "\n",
    "    if not os.path.isdir(song_folder_path):\n",
    "        print(f\"Warning: Directory not found at {song_folder_path}\")\n",
    "        return {}\n",
    "\n",
    "    # 2. Find all MIDI files in the directory\n",
    "    midi_filepaths = glob.glob(os.path.join(song_folder_path, '*.mid'))\n",
    "    midi_filepaths.extend(glob.glob(os.path.join(song_folder_path, '*.midi')))\n",
    "\n",
    "    if not midi_filepaths:\n",
    "        print(f\"Warning: No MIDI files found in {song_folder_path}\")\n",
    "        return {}\n",
    "\n",
    "    # 3. Process each MIDI file to generate embeddings\n",
    "    all_embeddings = {}\n",
    "    \n",
    "    \n",
    "\n",
    "    for midi_path in midi_filepaths:\n",
    "        filename = os.path.basename(midi_path)\n",
    "        print(f\"Processing {filename}...\")\n",
    "        \n",
    "        try:\n",
    "            # Load and quantize the MIDI file\n",
    "            midi_ns = note_seq.midi_file_to_note_sequence(midi_path)\n",
    "            print(f\"Processing {filename}...\")\n",
    "            cleaned_quantized_list = []\n",
    "            qpm = estimate_tempo_from_notes(midi_ns)\n",
    "            seconds_per_quarter = 60.0 / qpm\n",
    "            steps_per_quarter=mel_2bar_config.data_converter._steps_per_quarter \n",
    "            seconds_per_step = seconds_per_quarter / steps_per_quarter\n",
    "            num_steps_per_chunk = mel_2bar_config.hparams.max_seq_len\n",
    "            hop_size_in_seconds = num_steps_per_chunk * seconds_per_step # 32 / 4 = 8.0 seconds\n",
    "            cleaned_ms = make_monophonic(midi_ns)\n",
    "            \n",
    "            cleaned_ms = snap_chunk_notes_to_grid(cleaned_ms, steps_per_quarter)\n",
    "            cleaned_ms = set_program_for_all_notes(cleaned_ms, program_number=0)\n",
    "            \n",
    "            \n",
    "\n",
    "            if cleaned_ms.notes:\n",
    "                slices = sequences_lib.split_note_sequence(\n",
    "                    note_sequence=cleaned_ms,\n",
    "                    hop_size_seconds=hop_size_in_seconds  \n",
    "                )\n",
    "                for chunk in slices:\n",
    "                    cleaned_quantized_list.append(chunk)\n",
    "            embeddings=[]\n",
    "            \n",
    "            for chunk in cleaned_quantized_list:\n",
    "                try:\n",
    "                    embedding = mel_2bar.encode([chunk])\n",
    "                    embeddings.append(embedding)\n",
    "                except NoExtractedExamplesError as e:\n",
    "                    print(f\"Skipping chunk, insufficient note data\")\n",
    "                except MultipleExtractedExamplesError as e:\n",
    "                    print(f\"Skipping chunk, multiple examples extracted\")    \n",
    "                continue\n",
    "            if(len(embeddings)>0):\n",
    "                all_embeddings[filename] = embeddings\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  -> Could not process file {filename}. Error: {e}\")\n",
    "\n",
    "    return all_embeddings\n",
    "\n",
    "# --- Example Usage ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75356e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1d9d16a9da90c090809c153754823c2b.mid...\n",
      "Processing 1d9d16a9da90c090809c153754823c2b.mid...\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Processing 5dd29e99ed7bd3cc0c5177a6e9de22ea.mid...\n",
      "Processing 5dd29e99ed7bd3cc0c5177a6e9de22ea.mid...\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Processing b97c529ab9ef783a849b896816001748.mid...\n",
      "Processing b97c529ab9ef783a849b896816001748.mid...\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Processing dac3cdd0db6341d8dc14641e44ed0d44.mid...\n",
      "Processing dac3cdd0db6341d8dc14641e44ed0d44.mid...\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Generated embeddings for track TRAAAGR128F425B14B:\n",
      "  1d9d16a9da90c090809c153754823c2b.mid: 9 embeddings\n",
      "  5dd29e99ed7bd3cc0c5177a6e9de22ea.mid: 44 embeddings\n",
      "  b97c529ab9ef783a849b896816001748.mid: 34 embeddings\n",
      "  dac3cdd0db6341d8dc14641e44ed0d44.mid: 63 embeddings\n"
     ]
    }
   ],
   "source": [
    "track_id = \"TRAAAGR128F425B14B\"\n",
    "embeddings_dict = get_embeddings_for_song(track_id)\n",
    "print(f\"Generated embeddings for track {track_id}:\")\n",
    "for midi_file, embeddings in embeddings_dict.items():\n",
    "    print(f\"  {midi_file}: {len(embeddings)} embeddings\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d71808a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# --- NEW: Main Orchestrator Function ---\n",
    "def process_tracks_from_db(\n",
    "    start_line_to_process: int=0,\n",
    "    num_tracks_to_process: int = 1,\n",
    "    db_path: str='data_sets/track_metadata.db'\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Reads track_ids from an SQLite database, generates embeddings for each,\n",
    "    and returns a nested dictionary of all embeddings.\n",
    "\n",
    "    Args:\n",
    "        num_tracks_to_process (int, optional): The number of tracks to process.\n",
    "                                               If None, processes all tracks. Defaults to 1.\n",
    "        db_path (str): Path to the track_metadata.db SQLite file.\n",
    "       \n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are track_ids and values are the dictionaries\n",
    "        returned by get_embeddings_for_song.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(db_path):\n",
    "        print(f\"Error: Database not found at {db_path}\")\n",
    "        return {}\n",
    "\n",
    "    print(f\"Connecting to database: {db_path}\")\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # 1. Fetch the track_ids from the database\n",
    "    query = \"SELECT track_id FROM songs\" # Assuming the table is named 'songs'\n",
    "    if num_tracks_to_process is not None and num_tracks_to_process > 0:\n",
    "        num_tracks_to_query=num_tracks_to_process\n",
    "        query += f\" LIMIT {start_line_to_process}, {num_tracks_to_query}\"\n",
    "    \n",
    "    print(\"Fetching track_ids...\")\n",
    "    cursor.execute(query)\n",
    "    # Fetch all rows and flatten the list of tuples [('id1',), ('id2',)] -> ['id1', 'id2']\n",
    "    track_ids = [row[0] for row in cursor.fetchall()]\n",
    "    conn.close()\n",
    "    \n",
    "    if not track_ids:\n",
    "        print(\"No track_ids found in the database.\")\n",
    "        return {}\n",
    "\n",
    "    total_tracks = len(track_ids)\n",
    "    print(f\"Found {total_tracks} track_ids to process.\")\n",
    "\n",
    "    # 2. Iterate through track_ids and get embeddings for each\n",
    "    all_track_embeddings = {}\n",
    "    for i, track_id in enumerate(track_ids):\n",
    "        print(f\"\\n--- Processing track {i + 1}/{total_tracks}: {track_id} ---\")\n",
    "        \n",
    "        song_embeddings = get_embeddings_for_song(track_id)\n",
    "        \n",
    "        if song_embeddings:\n",
    "            all_track_embeddings[track_id] = song_embeddings\n",
    "            print(f\"-> Success: Found and processed {len(song_embeddings)} MIDI file(s) for this track.\")\n",
    "            \n",
    "    print(\"\\n--- Processing Complete ---\")\n",
    "    return all_track_embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613c83ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to database: data_sets/track_metadata.db\n",
      "Fetching track_ids...\n",
      "Found 100 track_ids to process.\n",
      "\n",
      "--- Processing track 1/100: TRAAAAK128F9318786 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAAK128F9318786\n",
      "\n",
      "--- Processing track 2/100: TRAAAAV128F421A322 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAAV128F421A322\n",
      "\n",
      "--- Processing track 3/100: TRAAAAW128F429D538 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAAW128F429D538\n",
      "\n",
      "--- Processing track 4/100: TRAAAAY128F42A73F0 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAAY128F42A73F0\n",
      "\n",
      "--- Processing track 5/100: TRAAABD128F429CF47 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAABD128F429CF47\n",
      "\n",
      "--- Processing track 6/100: TRAAACN128F9355673 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAACN128F9355673\n",
      "\n",
      "--- Processing track 7/100: TRAAACV128F423E09E ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAACV128F423E09E\n",
      "\n",
      "--- Processing track 8/100: TRAAADJ128F4287B47 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAADJ128F4287B47\n",
      "\n",
      "--- Processing track 9/100: TRAAADT12903CCC339 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAADT12903CCC339\n",
      "\n",
      "--- Processing track 10/100: TRAAADZ128F9348C2E ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAADZ128F9348C2E\n",
      "\n",
      "--- Processing track 11/100: TRAAAEA128F935A30D ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAEA128F935A30D\n",
      "\n",
      "--- Processing track 12/100: TRAAAED128E0783FAB ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAED128E0783FAB\n",
      "\n",
      "--- Processing track 13/100: TRAAAEF128F4273421 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAEF128F4273421\n",
      "\n",
      "--- Processing track 14/100: TRAAAEM128F93347B9 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAEM128F93347B9\n",
      "\n",
      "--- Processing track 15/100: TRAAAEW128F42930C0 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAEW128F42930C0\n",
      "\n",
      "--- Processing track 16/100: TRAAAFD128F92F423A ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAFD128F92F423A\n",
      "\n",
      "--- Processing track 17/100: TRAAAFI12903CE4F0E ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAFI12903CE4F0E\n",
      "\n",
      "--- Processing track 18/100: TRAAAFP128F931B4E3 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAFP128F931B4E3\n",
      "\n",
      "--- Processing track 19/100: TRAAAFW128F42A4CFD ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAFW128F42A4CFD\n",
      "\n",
      "--- Processing track 20/100: TRAAAGF12903CEC202 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAGF12903CEC202\n",
      "\n",
      "--- Processing track 21/100: TRAAAGR128F425B14B ---\n",
      "Processing 1d9d16a9da90c090809c153754823c2b.mid...\n",
      "Processing 1d9d16a9da90c090809c153754823c2b.mid...\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Skipping chunk, multiple examples extracted\n",
      "Processing 5dd29e99ed7bd3cc0c5177a6e9de22ea.mid...\n",
      "Processing 5dd29e99ed7bd3cc0c5177a6e9de22ea.mid...\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Processing b97c529ab9ef783a849b896816001748.mid...\n",
      "Processing b97c529ab9ef783a849b896816001748.mid...\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Processing dac3cdd0db6341d8dc14641e44ed0d44.mid...\n",
      "Processing dac3cdd0db6341d8dc14641e44ed0d44.mid...\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "Skipping chunk, insufficient note data\n",
      "-> Success: Found and processed 4 MIDI file(s) for this track.\n",
      "\n",
      "--- Processing track 22/100: TRAAAGW12903CC1049 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAGW12903CC1049\n",
      "\n",
      "--- Processing track 23/100: TRAAAHD128F42635A5 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAHD128F42635A5\n",
      "\n",
      "--- Processing track 24/100: TRAAAHE12903C9669C ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAHE12903C9669C\n",
      "\n",
      "--- Processing track 25/100: TRAAAHJ128F931194C ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAHJ128F931194C\n",
      "\n",
      "--- Processing track 26/100: TRAAAHO128F423BBE3 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAHO128F423BBE3\n",
      "\n",
      "--- Processing track 27/100: TRAAAHZ128E0799171 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAHZ128E0799171\n",
      "\n",
      "--- Processing track 28/100: TRAAAIC128F14A5138 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAIC128F14A5138\n",
      "\n",
      "--- Processing track 29/100: TRAAAIR128F1480971 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAIR128F1480971\n",
      "\n",
      "--- Processing track 30/100: TRAAAJG128F9308A25 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAJG128F9308A25\n",
      "\n",
      "--- Processing track 31/100: TRAAAJN128F428E437 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAJN128F428E437\n",
      "\n",
      "--- Processing track 32/100: TRAAAJO12903CAAC69 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAJO12903CAAC69\n",
      "\n",
      "--- Processing track 33/100: TRAAAKO128F426441E ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAKO128F426441E\n",
      "\n",
      "--- Processing track 34/100: TRAAAMG128F9318C5E ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAMG128F9318C5E\n",
      "\n",
      "--- Processing track 35/100: TRAAAMO128F1481E7F ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAMO128F1481E7F\n",
      "\n",
      "--- Processing track 36/100: TRAAAMQ128F1460CD3 ---\n",
      "Warning: Directory not found at data_sets\\lmd_melodies\\A\\A\\A\\TRAAAMQ128F1460CD3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example usage of the orchestrator function\n",
    "all_embeddings = process_tracks_from_db(\n",
    "    start_line_to_process=0,\n",
    "    num_tracks_to_process=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
