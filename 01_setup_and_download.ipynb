{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b34c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "import io\n",
    "\n",
    "# --- Step 1: Download the Pre-trained MusicVAE Model with Chunking ---\n",
    "\n",
    "# Define the model name and the URL\n",
    "# Note: Based on the URL, the model appears to be 'mel_2bar_big', not 'cat-mel_2bar_big'\n",
    "MODEL_NAME = 'mel_2bar_big' \n",
    "MODEL_URL = 'http://download.magenta.tensorflow.org/models/music_vae/checkpoints_bundled/mel_2bar_big.ckpt.tar'\n",
    "\n",
    "MODEL_DIR = 'models' # Directory to save the model\n",
    "CHECKPOINT_SUBDIR = os.path.join('download.magenta.tensorflow.org', 'models', 'music_vae', 'checkpoints')\n",
    "CHECKPOINT_BASE_NAME = os.path.join(MODEL_DIR, CHECKPOINT_SUBDIR, MODEL_NAME + '.ckpt') # The base name for the extracted checkpoint files\n",
    "CHECKPOINT_FILE_TO_CHECK = CHECKPOINT_BASE_NAME + '.index' # We check for the .index file as an indicator of successful extraction\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "# Check if the model is already downloaded\n",
    "if not os.path.exists(CHECKPOINT_FILE_TO_CHECK):\n",
    "    print(f'Downloading pre-trained model: {MODEL_NAME}...')\n",
    "    print(f'From URL: {MODEL_URL}')\n",
    "    \n",
    "    try:\n",
    "        # Use a session for better connection management\n",
    "        with requests.Session() as session:\n",
    "            # stream=True is crucial to avoid loading the whole file into memory\n",
    "            response = session.get(MODEL_URL, stream=True)\n",
    "            \n",
    "            # Raise an exception if the download fails\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Open the tar archive for reading from a stream ('r|')\n",
    "            # The fileobj is the raw response body, which is a file-like object\n",
    "            with tarfile.open(fileobj=response.raw, mode='r|*') as tar:\n",
    "                print(f'Starting extraction to: {MODEL_DIR}')\n",
    "                tar.extractall(path=MODEL_DIR)\n",
    "        \n",
    "        print(f'Successfully downloaded and extracted model to directory: {MODEL_DIR}')\n",
    "        # We check for the .ckpt.index file which is part of the actual output.\n",
    "        if os.path.exists(CHECKPOINT_FILE_TO_CHECK):\n",
    "             print(f'Verified checkpoint file exists at: {CHECKPOINT_FILE_TO_CHECK}')\n",
    "        else:\n",
    "             print(f'Warning: Expected checkpoint index file not found at {CHECKPOINT_FILE_TO_CHECK}. Please check the archive contents.')\n",
    "\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f'Error: Could not download model. An error occurred: {e}')\n",
    "    except tarfile.TarError as e:\n",
    "        print(f'Error: Could not extract the tar file. It may be corrupted or in an unexpected format. {e}')\n",
    "    except Exception as e:\n",
    "        print(f'An unexpected error occurred: {e}')\n",
    "\n",
    "else:\n",
    "    print(f'Model checkpoint index file already exists at: {CHECKPOINT_FILE_TO_CHECK}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bff850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import note_seq\n",
    "\n",
    "def triplets_to_note_sequence(triplets, qpm=120):\n",
    "    \"\"\"\n",
    "    Converts a list of (midi_note, onset_time, duration_time) triplets\n",
    "    into a note_seq.NoteSequence object.\n",
    "    Args:\n",
    "        triplets: A list of tuples, where each tuple is (midi_note, onset_time, duration_time).\n",
    "                  midi_note: MIDI pitch (0-127).\n",
    "                  onset_time: Start time of the note in seconds.\n",
    "                  duration_time: Duration of the note in seconds.\n",
    "        qpm: Quarter notes per minute for the NoteSequence tempo.\n",
    "    Returns:\n",
    "        A note_seq.NoteSequence object.\n",
    "    \"\"\"\n",
    "    note_sequence = note_seq.NoteSequence()\n",
    "    note_sequence.tempos.add().qpm = qpm\n",
    "    max_end_time = 0.0\n",
    "    for midi_note, onset_time, duration_time in triplets:\n",
    "        note = note_sequence.notes.add()\n",
    "        note.pitch = midi_note\n",
    "        note.start_time = onset_time\n",
    "        note.end_time = onset_time + duration_time\n",
    "        note.velocity = 100  # Default velocity\n",
    "        max_end_time = max(max_end_time, note.end_time)\n",
    "    note_sequence.total_time = max_end_time\n",
    "    return note_sequence\n",
    "\n",
    "print(\"Function `triplets_to_note_sequence` defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf102d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage:\n",
    "sample_triplets = [\n",
    "    (60, 0.0, 0.5),  # C4, start at 0s, duration 0.5s\n",
    "    (62, 0.5, 0.5),  # D4, start at 0.5s, duration 0.5s\n",
    "    (64, 1.0, 0.5),  # E4, start at 1.0s, duration 0.5s\n",
    "    (65, 1.5, 0.5),  # F4, start at 1.5s, duration 0.5s\n",
    "    (67, 2.0, 0.5),  # G4, start at 2.0s, duration 0.5s\n",
    "    (69, 2.5, 0.5),  # A4, start at 2.5s, duration 0.5s\n",
    "    (71, 3.0, 0.5),  # B4, start at 3.0s, duration 0.5s\n",
    "    (72, 3.5, 0.5)   # C5, start at 3.5s, duration 0.5s\n",
    "]\n",
    "sample_ns = triplets_to_note_sequence(sample_triplets)\n",
    "print(f\"Sample NoteSequence created with {len(sample_ns.notes)} notes and total time {sample_ns.total_time}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Importing libraries and loading the trained model')\n",
    "import magenta.music as mm\n",
    "from magenta.models.music_vae import configs\n",
    "from magenta.models.music_vae.trained_model import TrainedModel\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "import random\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
    "\n",
    "BASE_DIR=\"models/download.magenta.tensorflow.org/models/music_vae\"\n",
    "mel_2bar = TrainedModel(mel_2bar_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/mel_2bar_big.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c392d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled, embedding, sd_embedding = mel_2bar.encode([sample_ns])\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = mel_2bar.encode([sample_ns])\n",
    "print(embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
